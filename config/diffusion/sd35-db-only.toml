# Stable Diffusion 3.5 Medium configuration for db-only spectrograms (1 channel: dB magnitude)
# Uses flow matching with dual CLIP text encoders (CLIP-L + CLIP-G), skipping T5XXL for memory efficiency.
[settings]
config = "~/git/signal-diffusion/config/default.toml"
trainer = "diffusion"

[data]
output_type = "db-only"
data_type = "spectrogram"

[dataset]
name = "/data/data/signal-diffusion/processed/reweighted_meta_dataset_log_n2048_fs125"
train_split = "train"
val_split = "validation"
batch_size = 64
num_workers = 4
resolution = 256
center_crop = false
random_flip = false
image_column = "image"
caption_column = "caption"
num_classes = 0

[model]
name = "stable-diffusion-3.5-medium"
sample_size = 256
conditioning = "caption"
pretrained = "stabilityai/stable-diffusion-3.5-medium"

[model.extras]
skip_t5 = true
cfg_dropout = 0.1
train_text_encoder = false
latent_space = true

[model.lora]
enabled = false

[objective]
prediction_type = "vector_field"
flow_match_timesteps = 1000

[optimizer]
name = "adamw_8bit"
learning_rate = 1e-4
weight_decay = 1e-3
betas = [0.9, 0.99]

[scheduler]
name = "linear"
warmup_steps = 1000

[training]
seed = 42
epochs = 40
mixed_precision = "bf16"
gradient_checkpointing = true
gradient_accumulation_steps = 4
gradient_clip_norm = 1.0
snr_gamma = 5.0

log_every_steps = 10
checkpoint_interval = 1000
checkpoint_total_limit = 3

eval_strategy = "steps"
eval_num_steps = 1000
eval_num_examples = 8
eval_batch_size = 64
eval_mmd_samples = 1000
eval_mmd_fallback_ntrain = 1000

ema_use_warmup = true
ema_inv_gamma = 1
ema_power = 0.75
ema_decay = 0.9999
ema_update_after_step = 1000
compile_model = true
compile_mode = "default"

[logging]
tensorboard = true
run_name = "sd35-db-only"
log_dir = "runs/diffusion/tensorboard/sd35-db-only"
wandb_project = "signal-diffusion"

[inference]
denoising_steps = 25
cfg_scale = 1.5
