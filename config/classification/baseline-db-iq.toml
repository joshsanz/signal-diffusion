# Example config for multi-task classifiers with db-iq output type (3-channel RGB).
# This config is for use with output_type = "db-iq" in default.toml.
# The 3 channels are: dB-magnitude, real (I), and imaginary (Q) components.

[settings]
# Resolve relative to repository root so smoke script can run anywhere
config = "~/git/signal-diffusion/config/default.toml"
trainer = "classification"

[data]
output_type = "db-iq"
data_type = "spectrogram"

[dataset]
# name = "~/data/signal-diffusion/processed/reweighted_meta_dataset_log_n2048_fs125"
name = "/data/data/signal-diffusion/processed-iq/reweighted_meta_dataset_log_n2048_fs125"
train_split = "train"
val_split = "validation"
tasks = ["gender", "health", "age"]
batch_size = 64
num_workers = 2
shuffle = true

[model]
backbone = "cnn_light"
input_channels = 3  # 3 channels for db-iq: dB, I, Q
embedding_dim = 256
dropout = 0.5
depth = 3
layer_repeats = 2

[optimizer]
name = "adamw"
learning_rate = 3e-4
weight_decay = 1e-4
betas = [0.9, 0.995]

[scheduler]
# Available: "constant", "linear", "cosine"
name = "linear"
warmup_steps = 100

[scheduler.kwargs]
# num_cycles = 0.5  # For cosine
min_lr_ratio = 0.03  # For linear or cosine

[training]
epochs = 15
max_steps = -1
clip_grad_norm = 1.0
log_every_batches = 5
tensorboard = true
eval_strategy = "steps"
eval_steps = 100
checkpoint_strategy = "steps"
checkpoint_steps = 100
checkpoint_total_limit = 3
compile_model = true
compile_mode = "default"  # Options: "default", "reduce-overhead", "max-autotune"
swa_enabled = false
swa_extra_ratio = 0.34
swa_lr_frac = 0.25

[training.task_weights]
gender = 2.0
health = 1.0
age = 0.05  # Reduced to ~1/20 to balance with classification losses (~0.1-0.8) vs age MSE (~20-180)
