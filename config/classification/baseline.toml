# Example config for multi-task classifiers with db-only output type (1-channel grayscale).
# This config is for use with output_type = "db-only" in default.toml.

[settings]
# Resolve relative to repository root so smoke script can run anywhere
config = "~/git/signal-diffusion/config/default.toml"
trainer = "classification"

[data]
output_type = "db-only"
data_type = "spectrogram"

[dataset]
# name = "~/data/signal-diffusion/processed/reweighted_meta_dataset_log_n2048_fs125"
name = "/data/data/signal-diffusion/processed/reweighted_meta_dataset_log_n2048_fs125"
train_split = "train"
val_split = "validation"
tasks = ["gender", "health", "age"]
batch_size = 32
num_workers = 2
shuffle = true

[model]
backbone = "cnn_light"
input_channels = 1
embedding_dim = 384
dropout = 0.43
depth = 3
layer_repeats = 3

[optimizer]
name = "adamw"
learning_rate = 0.0002
weight_decay = 0.009
betas = [0.9, 0.995]

[scheduler]
# Available: "constant", "linear", "cosine"
name = "cosine"
warmup_steps = 100

[scheduler.kwargs]
# num_cycles = 0.5  # For cosine
min_lr_ratio = 0.03  # For linear or cosine

[training]
epochs = 10
max_steps = -1
clip_grad_norm = 1.0
log_every_batches = 5
tensorboard = true
eval_strategy = "steps"
eval_steps = 100
checkpoint_strategy = "steps"
checkpoint_steps = 100
checkpoint_total_limit = 3
compile_model = true
compile_mode = "default"  # Options: "default", "reduce-overhead", "max-autotune"
swa_enabled = false
swa_extra_ratio = 0.34
swa_lr_frac = 0.25
label_smoothing = 0.1

# Focal loss for imbalanced health task (set use_focal_loss_health=true to enable)
# Focal loss helps address severe class imbalance by down-weighting easy examples
# and focusing learning on hard examples
# use_focal_loss_health = true
# focal_alpha = 0.25  # Weight for minority class (lower = more weight)
# focal_gamma = 2.0   # Focusing parameter (higher = more focus on hard examples)

[training.task_weights]
gender = 2.0
health = 1.0
age = 0.05  # Reduced to ~1/20 to balance with classification losses (~0.1-0.8) vs age MSE (~20-180)
