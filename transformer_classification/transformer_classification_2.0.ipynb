{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "798b6201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for Tensor\n",
    "import csv\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "from tempfile import TemporaryDirectory\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "68ebe454",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls 'gdrive/My Drive/Muller Group Drive/Ear EEG/Drowsiness_Detection/classifier_TBME'\n",
    "#!ls C:\\Users\\arya_bastani\\Documents\\ear_eeg\\data\\ear_eeg_data\n",
    "ear_eeg_base_path = '/mnt/d/data/signal-diffusion/'\n",
    "ear_eeg_data_path = ear_eeg_base_path + 'eeg_classification_data/ear_eeg_data/ear_eeg_clean'\n",
    "\n",
    "%ls {ear_eeg_data_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c9432ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "\n",
    "#import support scripts: pull_data\n",
    "import support_scripts.read_in_ear_eeg as read_in_ear_eeg\n",
    "import support_scripts.read_in_labels as read_in_labels\n",
    "import support_scripts.eeg_filter as eeg_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e2d06940",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##################\n",
    "# READ-IN EAR EEG\n",
    "##################\n",
    "# NOTE, this takes a long time to run.\n",
    "# (It could be parallelized to reduce runtime)\n",
    "\n",
    "# name of spreadsheet with experiment details\n",
    "# details_spreadsheet = 'gdrive/My Drive/Muller Group Drive/Ear EEG/Drowsiness_Detection/classifier_TBME/classification_scripts/trial_details_spreadsheet_basic.csv'\n",
    "details_spreadsheet = ear_eeg_base_path + 'eeg_classification_data/ear_eeg_data/trial_details_spreadsheet_good.csv'\n",
    "\n",
    "# file path to ear eeg data (must be formated r'filepath\\\\')\n",
    "#data_filepath = r'C:\\Users\\Carolyn\\OneDrive\\Documents\\school\\berkeley\\research\\ear_eeg_classification_framework\\experimental_recordings\\drowsiness_studies\\ear_eeg\\\\'\n",
    "data_filepath = ear_eeg_base_path + 'eeg_classification_data/ear_eeg_data/ear_eeg_clean/'\n",
    "\n",
    "# user number or all users('all', 'ryan', 'justin', 'carolyn', 'ashwin', 'connor')\n",
    "input_users = 'all'\n",
    "\n",
    "# channels of eeg to read in for each trial (must include 5 and 11 if re-refernecing is enabled in the next block)\n",
    "data_chs = [1,2,3,4,5,7,8,9,10,11]\n",
    "\n",
    "# sampling frequency of system (fs=1000 for wandmini)\n",
    "fs = 1000\n",
    "\n",
    "# plot eeg data that is read in\n",
    "plot_raw_data_enable = False\n",
    "\n",
    "# call read in ear eeg\n",
    "all_raw_data, filenames, data_lengths, file_users, refs = read_in_ear_eeg.read_in_clean_data(details_spreadsheet, data_filepath, input_users, data_chs, fs, plot_raw_data_enable)\n",
    "# all_raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d63f0997",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_raw_data[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "510b7c84",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#################\n",
    "# READ-IN LABELS\n",
    "#################\n",
    "\n",
    "# Note: label read in will match Ear EEG read in\n",
    "# (same trials will be read in, and the experiment lengths will be the same)\n",
    "\n",
    "# file path to labels(must be formated r'filepath\\\\')\n",
    "#label_filepath = r'C:\\Users\\Carolyn\\OneDrive\\Documents\\school\\berkeley\\research\\ear_eeg_classification_framework\\experimental_recordings\\drowsiness_studies\\labels\\\\'\n",
    "label_filepath = ear_eeg_base_path + 'eeg_classification_data/ear_eeg_data/labels//'\n",
    "\n",
    "# plot the labels that are read in\n",
    "plot_labels_enable = False\n",
    "\n",
    "# call read in labels\n",
    "all_labels = read_in_labels.read_in_labels(filenames, data_lengths, label_filepath, plot_labels_enable)\n",
    "# all}|_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "003fc58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_labels[21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0d665100",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = eeg_filter.filter_studies(all_raw_data)\n",
    "\n",
    "\n",
    "print(len(all_raw_data))\n",
    "print(all_raw_data[0].shape)\n",
    "\n",
    "print(len(filtered_data))\n",
    "print(filtered_data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8646cf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No longer have a need for the original raw data so we delete\n",
    "del all_raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1185545e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data constants\n",
    "carolyn_indices = [0,1,2,3,4]\n",
    "ryan_indices = [5,6,7,8,9]\n",
    "justin_indices = [10,11,12,13,14]\n",
    "conor_indices = [15,16,17,18,19]\n",
    "avi_indices = [20,21]\n",
    "train_perc, val_perc, test_perc = 0.55, 0.30, .15\n",
    "train_ind = [2,3,4,8,9,12,13,14,15,17,18,19,21]\n",
    "val_ind = [1,6,11,16,20,7]\n",
    "test_ind = [0,5,10]\n",
    "\n",
    "# Model Constants\n",
    "window_size = 10 # Seconds\n",
    "sample_rate = 1000 # Hertz\n",
    "\n",
    "# Model Params\n",
    "seq_size = window_size * sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "38c58005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split up into train, val, and test datasets\n",
    "train_data, val_data, test_data = [],[],[]\n",
    "train_labels, val_labels, test_labels = [],[],[]\n",
    "\n",
    "\n",
    "for i in range(len(filtered_data)):\n",
    "    if i in train_ind:\n",
    "        train_data.append(filtered_data[i])\n",
    "        train_labels.append(all_labels[i])\n",
    "    elif i in val_ind:\n",
    "        val_data.append(filtered_data[i])\n",
    "        val_labels.append(all_labels[i])\n",
    "    else:\n",
    "        test_data.append(filtered_data[i])\n",
    "        test_labels.append(all_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "62056e4c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(train_data[0].T[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "02718772",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatt_data(data_set, seq_len):\n",
    "    index_sample_count_map = OrderedDict()\n",
    "    # Data needs to be input as (samples, channels), for ex: (2,400,000, 10)\n",
    "    formatted_datasets = []\n",
    "    for i in range(len(data_set)):\n",
    "        data = data_set[i]\n",
    "        data_length = data.shape[0]\n",
    "        num_seqs = int(np.floor(data_length/seq_len))\n",
    "        \n",
    "        index_sample_count_map[i] = num_seqs\n",
    "        \n",
    "        formatted_data = np.array(np.split(data[:num_seqs * seq_len], num_seqs))\n",
    "        formatted_datasets.append(formatted_data)\n",
    "    return formatted_datasets, index_sample_count_map\n",
    "\n",
    "def one_hot_encode(input):\n",
    "    b = np.zeros((int(input.size), int(input.max() + 1)))\n",
    "    b[np.arange(input.size), input] = 1\n",
    "    one_hot_labels = np.array(b)\n",
    "\n",
    "    return one_hot_labels\n",
    "\n",
    "def formatt_labels(labels_set, seq_len):\n",
    "    formatted_labels = []\n",
    "    for i in range(len(labels_set)):\n",
    "        labels = labels_set[i]\n",
    "        old_one_hot_labels = one_hot_encode(labels)\n",
    "        labels_length = old_one_hot_labels.shape[0]\n",
    "        num_seqs = int(np.floor(labels_length/seq_len))\n",
    "        \n",
    "        new_labels = np.array(np.split(old_one_hot_labels[:num_seqs*seq_len], num_seqs))\n",
    "        formatted_labels.append(new_labels)\n",
    "    return formatted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d0bfcb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the data\n",
    "seq_size = 128\n",
    "proc_train_X, train_seq_count_map = formatt_data(train_data, seq_size)\n",
    "#proc_val_X, val_seq_count_map = formatt_data(val_data, seq_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fd84720a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the labels\n",
    "proc_train_y = formatt_labels(train_labels, seq_size)\n",
    "\n",
    "#proc_val_y = formatt_labels(val_labels, seq_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2bac743e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(proc_train_X))\n",
    "print(proc_train_X[0].shape)\n",
    "proc_train_y[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ca2379a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data as tensors (THIS DATA IS FORMATTED REALLY POORLY, fix after the model stops getting overloaded)\n",
    "preproc_path = os.path.join(ear_eeg_base_path, \"saved_tensors\")\n",
    "os.makedirs(preproc_path, exist_ok=True)\n",
    "counter = 0\n",
    "sample_map = []\n",
    "for index in range(len(proc_train_X)):\n",
    "    dir_name = preproc_path + '/recording_' + str(index)\n",
    "    os.makedirs(dir_name, exist_ok=True)\n",
    "    N_sample_per_file = 100\n",
    "    cur_samples = proc_train_X[index]\n",
    "    cur_labels = proc_train_y[index]\n",
    "    cur_num_samples = cur_samples.shape[0]\n",
    "    cnt = 0\n",
    "    while cnt < cur_num_samples:\n",
    "        file_samples = cur_samples[cnt:cnt + N_sample_per_file, :, :]\n",
    "        file_labels = cur_labels[cnt:cnt + N_sample_per_file, :, :]\n",
    "        nsamps = file_samples.shape[0]  # May not be N_sample_per_file for final split\n",
    "        filename = f\"{counter}-{counter + nsamps - 1}.npz\"\n",
    "        np.savez(f\"{dir_name}/{filename}\", X=file_samples, y=file_labels)\n",
    "        sample_map.append((f\"recording_{index}/{filename}\", counter, counter + nsamps - 1))\n",
    "        cnt += nsamps\n",
    "        counter += nsamps\n",
    "\n",
    "with open(preproc_path + \"/metadata.csv\", \"w\") as fcsv:\n",
    "    writer = csv.writer(fcsv)\n",
    "    writer.writerow([\"filename\", \"start_sample\", \"final_sample\"])\n",
    "    writer.writerows(sample_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "67ae532b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data, proc_train_X, proc_train_y = [], [], []\n",
    "train_data, val_data, test_data = [], [], []\n",
    "train_labels, val_labels, test_labels = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "85eae030",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CacheDict(OrderedDict):\n",
    "    \"\"\"Dict with a limited length, ejecting LRUs as needed.\"\"\"\n",
    "\n",
    "    def __init__(self, *args, cache_len: int = 10, **kwargs):\n",
    "        assert cache_len > 0\n",
    "        self.cache_len = cache_len\n",
    "\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        super().__setitem__(key, value)\n",
    "        super().move_to_end(key)\n",
    "\n",
    "        while len(self) > self.cache_len:\n",
    "            oldkey = next(iter(self))\n",
    "            super().__delitem__(oldkey)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        val = super().__getitem__(key)\n",
    "        super().move_to_end(key)\n",
    "\n",
    "        return val\n",
    "    \n",
    "    \n",
    "# Fix ME INCORPORATE THE ADDITION OF THE MAP's\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, data_path, cache_mb=500):\n",
    "        'Initialization'\n",
    "        self.data_path = data_path\n",
    "        files, starts, stops = [], [], []\n",
    "        with open(data_path + \"/metadata.csv\", \"r\") as fcsv:\n",
    "            reader = csv.reader(fcsv)\n",
    "            header = next(reader)\n",
    "            for (f, s0, s1 ) in reader:\n",
    "                files.append(f)\n",
    "                starts.append(int(s0))\n",
    "                stops.append(int(s1))\n",
    "        self.start_inds = np.array(starts)\n",
    "        self.stop_inds = np.array(stops)\n",
    "        self.files = np.array(files)\n",
    "        # LRU cache for loaded data to try to reduce disk access\n",
    "        # Be careful, the memory foot print will grow per dataloader worker\n",
    "        cache_len = int(np.ceil(cache_mb / 1.2))  # 1.2 MB per loaded file\n",
    "        self.cache = CacheDict(cache_len=cache_len)\n",
    "        \n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return self.stop_inds[-1]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Load data and get label\n",
    "        file_idx = np.searchsorted(self.start_inds, index, side='right') - 1\n",
    "        filename = self.files[file_idx]\n",
    "        val = self.cache.get(filename, None)\n",
    "        if val is None:\n",
    "            data = np.load(os.path.join(self.data_path, filename))\n",
    "            X = torch.tensor(data['X']).float()\n",
    "            y = torch.tensor(data['y']).float()\n",
    "            self.cache[filename] = (X, y)\n",
    "        else:\n",
    "            X, y = val\n",
    "        offset = index - self.start_inds[file_idx]\n",
    "        return X[offset, :, :], y[offset, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "1dafe01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "# Parameters\n",
    "BATCH_SIZE = 256\n",
    "SHUFFLE = False\n",
    "NUM_WORKERS = 8\n",
    "\n",
    "max_epochs = 10\n",
    "\n",
    "# Datasets\n",
    "partition = train_seq_count_map# IDs\n",
    "labels = proc_train_y# Labels\n",
    "\n",
    "# Generators\n",
    "training_set = Dataset(preproc_path,)\n",
    "training_generator = torch.utils.data.DataLoader(training_set, batch_size=BATCH_SIZE, \n",
    "                                                 shuffle=SHUFFLE, num_workers=NUM_WORKERS)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "validation_set = Dataset(partition['validation'], labels)\n",
    "validation_generator = torch.utils.data.DataLoader(validation_set, **params)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "085ff5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hid_dim, n_layers, n_heads, pf_dim, dropout, batch_first):\n",
    "        super().__init__()\n",
    "        \n",
    "        #self.tok_embedding = nn.Embedding(input_dim, hid_dim)\n",
    "        self.pos_embedding = nn.Embedding(1000, hid_dim)  # position embedding\n",
    "        \n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(hid_dim, n_heads, pf_dim, dropout, batch_first=batch_first)\n",
    "        self.encoder = nn.TransformerEncoder(self.encoder_layer, n_layers)\n",
    "        \n",
    "        self.fc = nn.Linear(hid_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        # src: [src_len, batch_size]\n",
    "        \n",
    "        # create position tensor\n",
    "        #pos = torch.arange(0, src.shape[0]).unsqueeze(1).repeat(1, src.shape[1]).to(src.device)\n",
    "        \n",
    "        # embed tokens and positions\n",
    "        #tok_embedded = self.dropout(self.tok_embedding(src))  # [src_len, batch_size, hid_dim]\n",
    "        #pos_embedded = self.dropout(self.pos_embedding(pos))  # [src_len, batch_size, hid_dim]\n",
    "        #embedded = tok_embedded + pos_embedded\n",
    "        \n",
    "        # encode sequence\n",
    "        encoded = self.encoder(src)  # [src_len, batch_size, hid_dim]\n",
    "        # get final output and apply linear layer\n",
    "#         final_output = encoded.mean(dim=2)  # [batch_size, hid_dim]\n",
    "        logits = self.fc(encoded)  # [batch_size, output_dim]\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "7783aaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters\n",
    "INPUT_DIM = 10 #Not needed we're not embedding\n",
    "OUTPUT_DIM = 2\n",
    "HID_DIM = INPUT_DIM\n",
    "N_LAYERS = 4\n",
    "N_HEADS = 2\n",
    "PF_DIM = 256\n",
    "DROPOUT = 0.1\n",
    "BATCH_FIRST = True # True: (batch, seq, feature). False: (seq, batch, feature)\n",
    "\n",
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# create model instance\n",
    "model = TransformerClassifier(INPUT_DIM, OUTPUT_DIM, HID_DIM, N_LAYERS, N_HEADS, PF_DIM, DROPOUT, BATCH_FIRST)\n",
    "model = model.to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# define training and evaluation functions\n",
    "def train(model, iterator, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    for src, trg in iterator:        \n",
    "        src = src.to(device)\n",
    "        trg = trg.to(device)\n",
    "        output = model(src)\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    return loss\n",
    "\n",
    "def evaluate(model, iterator, criterion, device):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            src, trg = batch\n",
    "            src.to(device)\n",
    "            trg.to(device)\n",
    "            output = model(src)\n",
    "            loss = criterion(output, trg)\n",
    "            epoch_loss += loss.item()\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "a03d9929",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# define training loop\n",
    "N_EPOCHS = 10\n",
    "best_valid_loss = float('inf')\n",
    "for epoch in range(N_EPOCHS):\n",
    "    print(\"Epoch:\", epoch)\n",
    "    train_loss = train(model, training_generator, optimizer, criterion, device)\n",
    "#     valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "#     if valid_loss < best_valid_loss:\n",
    "#         best_valid_loss = valid_loss\n",
    "#         torch.save(model.state_dict(), 'model.pt')\n",
    "#     print(f'Epoch {epoch+1}: train loss={train_loss:.3f}, valid loss={valid_loss:.3f}')\n",
    "\n",
    "# load best model and evaluate on test set\n",
    "\n",
    "model.load_state_dict(torch.load('model.pt'))\n",
    "test_loss = evaluate(model, test_iterator, criterion)\n",
    "print(f'Test loss={test_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f8007c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c0efe4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
