{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1200f947",
   "metadata": {},
   "source": [
    "# Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "798b6201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for Tensor\n",
    "import csv\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from collections import OrderedDict\n",
    "from datetime import datetime\n",
    "from tempfile import TemporaryDirectory\n",
    "from typing import Tuple\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, Tensor\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import dataset\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee09d60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dog import DoG, LDoG\n",
    "from models import TransformerClassifier\n",
    "from datasets import EarDataset, EarEEGPreprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "68ebe454",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls 'gdrive/My Drive/Muller Group Drive/Ear EEG/Drowsiness_Detection/classifier_TBME'\n",
    "# !ls C:\\Users\\arya_bastani\\Documents\\ear_eeg\\data\\ear_eeg_data\n",
    "# ear_eeg_base_path = '/data/shared/signal-diffusion/'\n",
    "ear_eeg_base_path = '/mnt/d/data/signal-diffusion/'\n",
    "ear_eeg_data_path = ear_eeg_base_path + 'eeg_classification_data/ear_eeg_data/ear_eeg_clean'\n",
    "\n",
    "%ls {ear_eeg_data_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237c1f72",
   "metadata": {},
   "source": [
    "# Data Preprocessing (run once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca2379a1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "preprocessor = EarEEGPreprocessor(ear_eeg_base_path,)\n",
    "\n",
    "seq_len = 2000\n",
    "# %time preprocessor.preprocess(seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b939eb8e",
   "metadata": {},
   "source": [
    "# Models and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "196cef58",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "d = EarDataset(ear_eeg_base_path + \"ear_eeg_train\", 40)\n",
    "print(d[0][0].shape)\n",
    "print(d[0][1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6737589e",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8afb392b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_etas(logger, opt, step):\n",
    "    state = opt.state_dict()\n",
    "    scalars = {}\n",
    "    for i, p in enumerate(state['param_groups']):\n",
    "        etas = torch.stack(p['eta']).detach().cpu()\n",
    "        logger.add_histogram(f\"Eta.{i}\", etas, global_step=step)\n",
    "    return scalars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11cbda20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training and evaluation functions\n",
    "def train_epoch(model, iterator, optimizer, criterion, device, logger, progress):\n",
    "    global global_step\n",
    "    model.train()\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    for i, (src, trg) in enumerate(iterator):\n",
    "        # Send to device\n",
    "        src = src.to(device)\n",
    "        trg = trg.to(device)\n",
    "        # Run classifier & take step\n",
    "        output = model(src)\n",
    "        loss = criterion(output.permute(0, 2, 1), trg)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        # Log loss, accuracy\n",
    "        losses.append(loss.item())\n",
    "        y_hat = torch.argmax(output, dim=-1, keepdim=False)\n",
    "        accuracy = torch.sum(y_hat == trg) /  y_hat.nelement()\n",
    "        accuracies.append(accuracy.item())\n",
    "        logger.add_scalar(\"Loss/train\", loss.item(), global_step=global_step)\n",
    "        logger.add_scalar(\"Accuracy/train\", accuracy.item(), global_step=global_step)\n",
    "        if isinstance(optimizer, DoG) and global_step % 100 == 0:\n",
    "            log_etas(logger, optimizer, global_step)\n",
    "        # Update progress bar\n",
    "        progress.set_postfix({\"loss\": round(loss.item(), 5), \"acc\": round(accuracy.item(), 3)})\n",
    "        progress.update(1)\n",
    "        global_step += 1\n",
    "    return losses, accuracies\n",
    "\n",
    "def evaluate(model, iterator, criterion, device, logger):\n",
    "    global global_step\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "    N = len(iterator)\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            src, trg = batch\n",
    "            src = src.to(device)\n",
    "            trg = trg.to(device)\n",
    "            output = model(src)\n",
    "            loss = criterion(output.permute(0, 2, 1), trg)\n",
    "            epoch_loss += loss.item()\n",
    "            y_hat = torch.argmax(output, dim=-1, keepdim=False)\n",
    "            accuracy = torch.sum(y_hat == trg) /  y_hat.nelement()\n",
    "            epoch_accuracy += accuracy.item()\n",
    "    logger.add_scalar(\"Loss/validate\", epoch_loss / N, global_step=global_step)\n",
    "    logger.add_scalar(\"Accuracy/validate\", epoch_accuracy / N, global_step=global_step)\n",
    "    return epoch_loss / N, epoch_accuracy / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1dafe01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "BATCH_SIZE = 256\n",
    "SHUFFLE = True\n",
    "NUM_WORKERS = 8\n",
    "CONTEXT_SAMPS = 40\n",
    "\n",
    "# Datasets\n",
    "training_set = Dataset(ear_eeg_base_path + \"ear_eeg_train\", CONTEXT_SAMPS)\n",
    "validation_set = Dataset(ear_eeg_base_path + \"ear_eeg_val\", CONTEXT_SAMPS)\n",
    "test_set = Dataset(ear_eeg_base_path + \"ear_eeg_test\", CONTEXT_SAMPS)\n",
    "training_generator = torch.utils.data.DataLoader(training_set, batch_size=BATCH_SIZE, \n",
    "                                                 shuffle=SHUFFLE, num_workers=NUM_WORKERS,\n",
    "                                                 pin_memory=True, persistent_workers=True)\n",
    "validation_generator = torch.utils.data.DataLoader(validation_set, batch_size=BATCH_SIZE, \n",
    "                                                   shuffle=SHUFFLE, num_workers=NUM_WORKERS,\n",
    "                                                   pin_memory=True, persistent_workers=True)\n",
    "test_generator = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE, \n",
    "                                             shuffle=SHUFFLE, num_workers=NUM_WORKERS,\n",
    "                                             pin_memory=True, persistent_workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7783aaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters\n",
    "INPUT_DIM = 10 * CONTEXT_SAMPS\n",
    "OUTPUT_DIM = 2\n",
    "HID_DIM = INPUT_DIM // 4\n",
    "N_LAYERS = 4\n",
    "N_HEADS = 4\n",
    "FF_DIM = 256\n",
    "DROPOUT = 0.1\n",
    "BATCH_FIRST = True # True: (batch, seq, feature). False: (seq, batch, feature)\n",
    "\n",
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# create model instance\n",
    "model = TransformerClassifier(INPUT_DIM, OUTPUT_DIM, HID_DIM, N_LAYERS, N_HEADS, FF_DIM, DROPOUT, BATCH_FIRST)\n",
    "model = model.to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = LDoG(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a03d9929",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Log statistics\n",
    "tbsw = SummaryWriter(log_dir=\"./tensorboard_logs/\" + \"txfmr_classifier-\" + datetime.now().isoformat(sep='_'), \n",
    "                     comment=\"txfmr_classifier\")\n",
    "\n",
    "# Training loop\n",
    "N_EPOCHS = 500\n",
    "VAL_EVERY = 10\n",
    "best_valid_acc = float('inf')\n",
    "epoch_losses = []\n",
    "best_epoch = 0\n",
    "global_step = 0\n",
    "prog = tqdm(total=len(training_generator) * N_EPOCHS)\n",
    "for epoch in range(N_EPOCHS):\n",
    "#     print(\"Epoch:\", epoch, file=sys.stderr)\n",
    "    train_losses, train_accs = train_epoch(model, training_generator, optimizer, criterion, device, tbsw, prog)\n",
    "    if epoch % VAL_EVERY == 0 or epoch == N_EPOCHS - 1:\n",
    "        valid_loss, valid_acc = evaluate(model, validation_generator, criterion, device, tbsw)\n",
    "        if valid_acc < best_valid_acc:\n",
    "            best_valid_acc = valid_acc\n",
    "            best_epoch = epoch\n",
    "            torch.save(model.state_dict(), f'model.pt')\n",
    "        prog.set_postfix({\"Epoch\": epoch+ 1, \"TAcc\": round(train_accs[-1], 3), \"VAcc\": round(valid_acc, 3)})\n",
    "    else:\n",
    "        valid_loss = None\n",
    "    epoch_losses.append((train_losses, valid_loss))\n",
    "# Finish progress bar\n",
    "prog.close()\n",
    "\n",
    "# load best model and evaluate on test set\n",
    "\n",
    "model.load_state_dict(torch.load(f'model.pt'))\n",
    "test_loss, test_acc = evaluate(model, test_generator, criterion, device, tbsw)\n",
    "print(f'Test loss={test_loss:.3f}; test accuracy={test_acc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c57268c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561b8a12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
