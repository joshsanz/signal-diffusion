{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "798b6201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Imports for Tensor\n",
    "import math\n",
    "import os\n",
    "from tempfile import TemporaryDirectory\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68ebe454",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls 'gdrive/My Drive/Muller Group Drive/Ear EEG/Drowsiness_Detection/classifier_TBME'\n",
    "#!ls C:\\Users\\arya_bastani\\Documents\\ear_eeg\\data\\ear_eeg_data\n",
    "ear_eeg_data_path = '/data/shared/signal-diffusion/eeg_classification_data/ear_eeg_data/ear_eeg_clean'\n",
    "\n",
    "%ls {ear_eeg_data_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c9432ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "\n",
    "#import support scripts: pull_data\n",
    "import support_scripts.read_in_ear_eeg as read_in_ear_eeg\n",
    "import support_scripts.read_in_labels as read_in_labels\n",
    "import support_scripts.eeg_filter as eeg_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2d06940",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# READ-IN EAR EEG\n",
    "##################\n",
    "# NOTE, this takes a long time to run.\n",
    "# (It could be parallelized to reduce runtime)\n",
    "\n",
    "# name of spreadsheet with experiment details\n",
    "# details_spreadsheet = 'gdrive/My Drive/Muller Group Drive/Ear EEG/Drowsiness_Detection/classifier_TBME/classification_scripts/trial_details_spreadsheet_basic.csv'\n",
    "details_spreadsheet = r'/data/shared/signal-diffusion/eeg_classification_data/ear_eeg_data/trial_details_spreadsheet_good.csv'\n",
    "\n",
    "# file path to ear eeg data (must be formated r'filepath\\\\')\n",
    "#data_filepath = r'C:\\Users\\Carolyn\\OneDrive\\Documents\\school\\berkeley\\research\\ear_eeg_classification_framework\\experimental_recordings\\drowsiness_studies\\ear_eeg\\\\'\n",
    "data_filepath = r'/data/shared/signal-diffusion/eeg_classification_data/ear_eeg_data/ear_eeg_clean//'\n",
    "\n",
    "# user number or all users('all', 'ryan', 'justin', 'carolyn', 'ashwin', 'connor')\n",
    "input_users = 'all'\n",
    "\n",
    "# channels of eeg to read in for each trial (must include 5 and 11 if re-refernecing is enabled in the next block)\n",
    "data_chs = [1,2,3,4,5,7,8,9,10,11]\n",
    "\n",
    "# sampling frequency of system (fs=1000 for wandmini)\n",
    "fs = 1000\n",
    "\n",
    "# plot eeg data that is read in\n",
    "plot_raw_data_enable = False\n",
    "\n",
    "# call read in ear eeg\n",
    "all_raw_data, filenames, data_lengths, file_users, refs = read_in_ear_eeg.read_in_clean_data(details_spreadsheet, data_filepath, input_users, data_chs, fs, plot_raw_data_enable)\n",
    "#all_raw_data = np.array(all_raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d63f0997",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_raw_data[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "510b7c84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#################\n",
    "# READ-IN LABELS\n",
    "#################\n",
    "\n",
    "# Note: label read in will match Ear EEG read in\n",
    "# (same trials will be read in, and the experiment lengths will be the same)\n",
    "\n",
    "# file path to labels(must be formated r'filepath\\\\')\n",
    "#label_filepath = r'C:\\Users\\Carolyn\\OneDrive\\Documents\\school\\berkeley\\research\\ear_eeg_classification_framework\\experimental_recordings\\drowsiness_studies\\labels\\\\'\n",
    "label_filepath =  r'/data/shared/signal-diffusion/eeg_classification_data/ear_eeg_data/labels//'\n",
    "\n",
    "# plot the labels that are read in\n",
    "plot_labels_enable = False\n",
    "\n",
    "# call read in labels\n",
    "all_labels = read_in_labels.read_in_labels(filenames, data_lengths, label_filepath, plot_labels_enable)\n",
    "all_labels = np.array(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "003fc58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_labels[21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d665100",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = eeg_filter.filter_studies(all_raw_data)\n",
    "\n",
    "\n",
    "print(len(all_raw_data))\n",
    "print(all_raw_data[0].shape)\n",
    "\n",
    "print(len(filtered_data))\n",
    "print(filtered_data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8646cf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No longer have a need for the original raw data so we delete\n",
    "del all_raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65eb97b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys. getsizeof(filtered_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1185545e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data constants\n",
    "carolyn_indices = [0,1,2,3,4]\n",
    "ryan_indices = [5,6,7,8,9]\n",
    "justin_indices = [10,11,12,13,14]\n",
    "conor_indices = [15,16,17,18,19]\n",
    "avi_indices = [20,21]\n",
    "train_perc, val_perc, test_perc = 0.55, 0.30, .15\n",
    "train_ind = [2,3,4,8,9,12,13,14,15,17,18,19,21]\n",
    "val_ind = [1,6,11,16,20,7]\n",
    "test_ind = [0,5,10]\n",
    "\n",
    "# Model Constants\n",
    "window_size = 10 # Seconds\n",
    "sample_rate = 1000 # Hertz\n",
    "\n",
    "# Model Params\n",
    "seq_size = window_size * sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38c58005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split up into train, val, and test datasets\n",
    "train_data, val_data, test_data = [],[],[]\n",
    "train_labels, val_labels, test_labels = [],[],[]\n",
    "\n",
    "\n",
    "for i in range(len(filtered_data)):\n",
    "    if i in train_ind:\n",
    "        train_data.append(filtered_data[i])\n",
    "        train_labels.append(all_labels[i])\n",
    "    elif i in val_ind:\n",
    "        val_data.append(filtered_data[i])\n",
    "        val_labels.append(all_labels[i])\n",
    "    else:\n",
    "        test_data.append(filtered_data[i])\n",
    "        test_labels.append(all_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62056e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data[0].T[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02718772",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatt_data(data_set, seq_len):\n",
    "    # Data needs to be input as (samples, channels), for ex: (2,400,000, 10)\n",
    "    new_dataset = []\n",
    "    for data in data_set:\n",
    "        data = data.T\n",
    "        #print(data.shape)\n",
    "        new_data = []\n",
    "        row_len = data.shape[1]\n",
    "        #print(row_len)\n",
    "        #print(seq_len)\n",
    "        num_seqs = int(row_len/seq_len)\n",
    "        #print(\"bad\")\n",
    "        for row in data:\n",
    "            #print(num_seqs)\n",
    "            new_row = np.split(row, num_seqs)\n",
    "            new_data.append(new_row)\n",
    "            #print(\"bad\")\n",
    "        new_data = np.array(new_data).T\n",
    "        #print(new_data.shape)\n",
    "        new_dataset.append(new_data)\n",
    "        \n",
    "    return new_dataset\n",
    "\n",
    "def one_hot_encode(input):\n",
    "    one_hot_formatted_seq_labels = []\n",
    "    b = np.zeros((int(input.size), int(input.max() + 1)))\n",
    "    b[np.arange(input.size), input] = 1\n",
    "    one_hot_labels = np.array(b)\n",
    "\n",
    "    return one_hot_labels\n",
    "\n",
    "def formatt_labels(labels_set, seq_size):\n",
    "    processed_labels = []\n",
    "    for i in range(len(labels_set)):\n",
    "        old_one_hot_labels = one_hot_encode(train_labels[i])\n",
    "        new_labels = old_one_hot_labels[::seq_size]    \n",
    "        processed_labels.append(new_labels)\n",
    "    return processed_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dea84fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(train_data).shape)\n",
    "print(np.array(train_data).T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0bfcb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_train = formatt_data(train_data, seq_size)\n",
    "proc_val = formatt_data(val_data, seq_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0f94b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(proc_train[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd84720a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# format the labels\n",
    "processed_train_labels = formatt_labels(train_labels, seq_size)\n",
    "processed_val_labels = formatt_labels(val_labels, seq_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2bac743e",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train_labels[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0bb9541e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "proc_train_new = [study[::4] for study in proc_train]\n",
    "processed_train_labels_new = [study[::4] for study in processed_train_labels]\n",
    "\n",
    "proc_val_new = [study[::4] for study in proc_val]\n",
    "processed_val_labels_new = [study[::4] for study in processed_val_labels]\n",
    "\n",
    "print(proc_train_new[0].shape)\n",
    "\n",
    "print(processed_train_labels_new[0].shape)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "286553c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_train_new = [study[:512] for study in proc_train]\n",
    "\n",
    "proc_val_new = [study[:512] for study in proc_val]\n",
    "\n",
    "print(proc_train_new[0].shape)\n",
    "\n",
    "print(processed_train_labels[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca2379a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the data as tensors (THIS DATA IS FORMATTED REALLY POORLY, fix after the model stops getting overloaded)\n",
    "batch_ids = []\n",
    "\n",
    "for index in range(len(proc_train_new)):\n",
    "    batch_id = 'saved_tensors/batch_' + str(index) + '.pt'\n",
    "    batch_ids.append(index)\n",
    "\n",
    "    torch.save(proc_train_new[index], batch_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "565c84e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.autograd import Variable \n",
    "\n",
    "# # Turn into tensors\n",
    "\n",
    "# X_train_tensors = [torch.from_numpy(batch) for batch in proc_train_new]\n",
    "# y_train_tensors = [torch.from_numpy(batch) for batch in processed_train_labels_new]\n",
    "\n",
    "# X_val_tensors = [torch.from_numpy(batch) for batch in proc_val_new]\n",
    "# y_val_tensors = [torch.from_numpy(batch) for batch in processed_val_labels_new]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "71c772a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding Layer\n",
    "# In this implementation we will do a sort of raw embedding for the system\n",
    "# We will treat each channel as a word, and define the length of each word as the window size we are referencing\n",
    "# The vectors of each channel will be strung together in order to make a \"sentence\" which will then have positional \n",
    "# encoding added to it, and from there we'll pass it into the \n",
    "\n",
    "\"\"\"\n",
    "class AryaEmbed():\n",
    "    def __init__(vect_len: int):\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "85eae030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "  'Characterizes a dataset for PyTorch'\n",
    "  def __init__(self, list_IDs, labels):\n",
    "        'Initialization'\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "\n",
    "  def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.list_IDs)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "\n",
    "        # Load data and get label\n",
    "        X = torch.load('saved_tensors/batch_' + str(index) + '.pt')\n",
    "        y = self.labels[index]\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1dafe01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Parameters\n",
    "BATCH_SIZE = 512\n",
    "SHUFFLE = False\n",
    "NUM_WORKERS = 1\n",
    "\n",
    "max_epochs = 10\n",
    "\n",
    "# Datasets\n",
    "partition = batch_ids# IDs\n",
    "labels = processed_train_labels# Labels\n",
    "\n",
    "# Generators\n",
    "training_set = Dataset(partition, labels)\n",
    "training_generator = torch.utils.data.DataLoader(training_set, BATCH_SIZE, SHUFFLE, NUM_WORKERS)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "validation_set = Dataset(partition['validation'], labels)\n",
    "validation_generator = torch.utils.data.DataLoader(validation_set, **params)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "085ff5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hid_dim, n_layers, n_heads, pf_dim, dropout, batch_firsty):\n",
    "        super().__init__()\n",
    "        \n",
    "        #self.tok_embedding = nn.Embedding(input_dim, hid_dim)\n",
    "        self.pos_embedding = nn.Embedding(1000, hid_dim)  # position embedding\n",
    "        \n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(hid_dim, n_heads, pf_dim, dropout, batch_first=batch_firsty)\n",
    "        self.encoder = nn.TransformerEncoder(self.encoder_layer, n_layers)\n",
    "        \n",
    "        self.fc = nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        # src: [src_len, batch_size]\n",
    "        \n",
    "        # create position tensor\n",
    "        #pos = torch.arange(0, src.shape[0]).unsqueeze(1).repeat(1, src.shape[1]).to(src.device)\n",
    "        \n",
    "        # embed tokens and positions\n",
    "        #tok_embedded = self.dropout(self.tok_embedding(src))  # [src_len, batch_size, hid_dim]\n",
    "        #pos_embedded = self.dropout(self.pos_embedding(pos))  # [src_len, batch_size, hid_dim]\n",
    "        #embedded = tok_embedded + pos_embedded\n",
    "        \n",
    "        # encode sequence\n",
    "        \n",
    "        print(type(src))\n",
    "        \n",
    "        encoded = self.encoder(src.double())  # [src_len, batch_size, hid_dim]\n",
    "        \n",
    "        # get final output and apply linear layer\n",
    "        final_output = encoded.mean(dim=0)  # [batch_size, hid_dim]\n",
    "        logits = self.fc(final_output)  # [batch_size, output_dim]\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7783aaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters\n",
    "INPUT_DIM = 10 #Not needed we're not embedding\n",
    "OUTPUT_DIM = 2\n",
    "HID_DIM = INPUT_DIM\n",
    "N_LAYERS = 4\n",
    "N_HEADS = 2\n",
    "PF_DIM = 512\n",
    "DROPOUT = 0.1\n",
    "BATCH_FIRST = False #True: (batch, seq, feature). False: (seq, batch, feature)\n",
    "\n",
    "# create model instance\n",
    "model = TransformerClassifier(INPUT_DIM, OUTPUT_DIM, HID_DIM, N_LAYERS, N_HEADS, PF_DIM, DROPOUT, BATCH_FIRST)\n",
    "\n",
    "# define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# define training and evaluation functions\n",
    "def train(model, iterator, optimizer, criterion):\n",
    "    model.train()\n",
    "    for src, trg in iterator:        \n",
    "        print(\"src shape: \", src.shape)\n",
    "        print(\"src shape: \", trg.shape)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(src)\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return loss\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            src, trg = batch\n",
    "            output = model(src)\n",
    "            loss = criterion(output, trg)\n",
    "            epoch_loss += loss.item()\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a03d9929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training loop\n",
    "N_EPOCHS = 10\n",
    "best_valid_loss = float('inf')\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss = train(model, training_generator, optimizer, criterion)\n",
    "#     valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "#     if valid_loss < best_valid_loss:\n",
    "#         best_valid_loss = valid_loss\n",
    "#         torch.save(model.state_dict(), 'model.pt')\n",
    "#     print(f'Epoch {epoch+1}: train loss={train_loss:.3f}, valid loss={valid_loss:.3f}')\n",
    "\n",
    "# load best model and evaluate on test set\n",
    "model.load_state_dict(torch.load('model.pt'))\n",
    "test_loss = evaluate(model, test_iterator, criterion)\n",
    "print(f'Test loss={test_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff8638a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_tensors.shape)\n",
    "  train_pred = lstm.forward(X_train_tensors) #forward pass\n",
    "  print(\"pre soft train_pred: \", train_pred.shape)\n",
    "  softmaxed_train_pred = train_pred.argmax(dim=2,keepdim=False)\n",
    "  print(\"post soft train_pred: \", softmaxed_train_pred.shape)\n",
    "\n",
    "\n",
    "\n",
    "  optimizer.zero_grad() #caluclate the gradient, manually setting to 0\n",
    "\n",
    "  #print(type(train_pred[0][0][0]))\n",
    "  #print(type(y_train_tensors[0][0][0]))\n",
    "\n",
    "  print(train_pred.shape)\n",
    "  print(y_train_tensors.shape)\n",
    "\n",
    "\n",
    "  train_loss = criterion(train_pred, y_train_tensors)\n",
    "  train_loss.backward() #calculates the loss of the loss function\n",
    "  optimizer.step() #improve from loss, i.e backprop\n",
    "\n",
    "\n",
    "  # Run on validation\n",
    "  test_pred = lstm.forward(X_test_tensors) #forward pass\n",
    "  #test_loss = criterion(test_pred.type(torch.LongTensor), y_test_tensors.type(torch.LongTensor))\n",
    "  test_loss = criterion(test_pred, y_test_tensors)\n",
    "\n",
    "  softmaxed_test_pred = test_pred.argmax(dim=2,keepdim=False)\n",
    "\n",
    "\n",
    "  print(\"softmaxed_train_pred; \", softmaxed_train_pred.shape)\n",
    "  print(\"y_train: \", y_train.shape)\n",
    "\n",
    "\n",
    "  train_accuracy = accuracy_score(softmaxed_train_pred, y_train)\n",
    "  train_accuracies.append(train_accuracy)\n",
    "  train_losses.append(train_loss.item())\n",
    "\n",
    "  test_accuracy = accuracy_score(softmaxed_test_pred, y_test)\n",
    "  test_accuracies.append(test_accuracy)\n",
    "  test_losses.append(test_loss.item())\n",
    "\n",
    "  #test_sensitivity, test_specificity = sensitivy_specificity_results(softmaxed_test_pred, y_test, False)\n",
    "  #test_sensitivities.append(test_sensitivity)\n",
    "  #test_specificities.append(test_specificity)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b54e3ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afef27fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
