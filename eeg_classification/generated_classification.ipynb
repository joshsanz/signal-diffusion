{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1200f947",
   "metadata": {},
   "source": [
    "# Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "798b6201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for Tensor\n",
    "import csv\n",
    "import itertools\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import shutil\n",
    "import sys\n",
    "from collections import OrderedDict\n",
    "from datetime import datetime\n",
    "from tempfile import TemporaryDirectory\n",
    "from typing import Tuple\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, Tensor\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import dataset\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from diffusers import StableDiffusionPipeline\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee09d60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.dog import DoG, LDoG, PDoG\n",
    "from models import CNNClassifier\n",
    "from common.eeg_datasets import MathSpectrumDataset, MathPreprocessor\n",
    "from training import train_class, evaluate_class, TrainingConfig\n",
    "from visualization import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68ebe454",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls 'gdrive/My Drive/Muller Group Drive/Ear EEG/Drowsiness_Detection/classifier_TBME'\n",
    "# !ls C:\\Users\\arya_bastani\\Documents\\ear_eeg\\data\\ear_eeg_data\n",
    "ear_eeg_base_path = '/data/shared/signal-diffusion/'\n",
    "# ear_eeg_base_path = '/mnt/d/data/signal-diffusion/'\n",
    "ear_eeg_data_path = ear_eeg_base_path + 'eeg_classification_data/ear_eeg_data/ear_eeg_clean'\n",
    "math_data_path = '/data/shared/signal-diffusion/eeg_math/raw_eeg'\n",
    "# math_data_path = '/mnt/d/data/signal-diffusion/eeg_math/raw_eeg'\n",
    "%ls {ear_eeg_data_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237c1f72",
   "metadata": {},
   "source": [
    "# Data Preprocessing (run once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "101e161a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nsamps = 2000\n",
    "preprocessor = MathPreprocessor(math_data_path, nsamps)\n",
    "\n",
    "samps_per_file = 20\n",
    "%time preprocessor.preprocess(samps_per_file, 0.9, 0.05, 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b939eb8e",
   "metadata": {},
   "source": [
    "# Models and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "317852fc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "d = MathSpectrumDataset(math_data_path + \"/train\", 512, 80,)\n",
    "print(d[0][0].shape)\n",
    "print(d[0][1].shape)\n",
    "print(len(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "989d8f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = torch.utils.data.DataLoader(d, batch_size=16, shuffle=True,)\n",
    "S, y = next(iter(dl))\n",
    "print(S.shape, y.shape)\n",
    "print(S.max(), S.min(), S.mean(), S.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a626f06",
   "metadata": {},
   "source": [
    "# Math EEG Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66b3d4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "BATCH_SIZE = 64\n",
    "SHUFFLE = True\n",
    "NUM_WORKERS = 16\n",
    "N_TOKENS = 128\n",
    "RESOLUTION = 512\n",
    "HOP_LENGTH = 80\n",
    "persistent = NUM_WORKERS > 0\n",
    "\n",
    "# Datasets\n",
    "train_set = MathSpectrumDataset(math_data_path + \"/train\", RESOLUTION, HOP_LENGTH)\n",
    "val_set = MathSpectrumDataset(math_data_path + \"/val\", RESOLUTION, HOP_LENGTH)\n",
    "test_set = MathSpectrumDataset(math_data_path + \"/test\", RESOLUTION, HOP_LENGTH)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE, \n",
    "                                           shuffle=SHUFFLE, num_workers=NUM_WORKERS,\n",
    "                                           pin_memory=True, persistent_workers=persistent)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=BATCH_SIZE, \n",
    "                                         shuffle=SHUFFLE, num_workers=NUM_WORKERS,\n",
    "                                         pin_memory=True, persistent_workers=persistent)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE, \n",
    "                                          shuffle=SHUFFLE, num_workers=NUM_WORKERS,\n",
    "                                          pin_memory=True, persistent_workers=persistent)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "414ea53c",
   "metadata": {},
   "source": [
    "import time\n",
    "# Warmup\n",
    "for i, (X, y) in enumerate(train_loader):\n",
    "    count = i\n",
    "    if i >= 100:\n",
    "        break\n",
    "# Measure\n",
    "t0 = time.time()\n",
    "count = 0\n",
    "for i, (X, y) in enumerate(train_loader):\n",
    "    count = i\n",
    "    if i >= 100:\n",
    "        break\n",
    "t1 = time.time()\n",
    "print(f\"Achieved {(t1 - t0) / count} s/it\")\n",
    "print(\"or\")\n",
    "print(f\"Achieved {count / (t1 - t0)} it/s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "787c1b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters\n",
    "OUTPUT_DIM = 4\n",
    "DROPOUT = 0.25\n",
    "BATCH_FIRST = True # True: (batch, seq, feature). False: (seq, batch, feature)\n",
    "WEIGHT_DECAY = 0.0001\n",
    "\n",
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39683b1d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Runtime training parameters\n",
    "opt_options = [\n",
    "    torch.optim.AdamW,\n",
    "#     LDoG,\n",
    "    # PDoG,\n",
    "#     DoG,\n",
    "]\n",
    "# restart_options = [0, 100]\n",
    "restart_options = [0]\n",
    "# max_eta_options = [None, 100.]\n",
    "max_eta_options = [None]\n",
    "# decay_options = [0.0, 0.0001, 0.001]\n",
    "decay_options = [0.0001]\n",
    "# decouple_options = [True, False]\n",
    "decouple_options = [True]\n",
    "\n",
    "# Run for each option combo\n",
    "seen_decays = set()\n",
    "combos = list(itertools.product(\n",
    "    opt_options, decay_options, restart_options, max_eta_options, decouple_options))\n",
    "print(f\"Running {len(combos)} hyperparameter tests\")\n",
    "for (opt, decay, restart, max_eta, decouple) in combos:\n",
    "    # Only run once for AdamW, decay combos\n",
    "    if opt == torch.optim.AdamW:\n",
    "        if decay in seen_decays:\n",
    "            continue\n",
    "        seen_decays.add(decay)\n",
    "\n",
    "    # Create model instance\n",
    "    model = CNNClassifier(1, OUTPUT_DIM,)\n",
    "    model = model.to(device)    \n",
    "    if opt == torch.optim.AdamW:\n",
    "        optimizer = opt(model.parameters(), lr=1e-3, weight_decay=decay)\n",
    "    else:\n",
    "        optimizer = opt(model.parameters(), weight_decay=decay, max_eta=max_eta, decouple_weight_decay=decouple)\n",
    "\n",
    "    # Create training configuration\n",
    "    ARGS = TrainingConfig(epochs=300, val_every_epochs=10, opt_restart_every=restart)\n",
    "\n",
    "    # Log statistics\n",
    "    postfix = \"\"\n",
    "    if isinstance(optimizer, DoG):\n",
    "        postfix = f\"_restart{restart}_etamax{max_eta}_decouple{str(int(decouple))}\"\n",
    "    comment = f\"cnnclass_{str(type(optimizer)).split('.')[-1][:-2]}_decay{decay}{postfix}\"\n",
    "    tbsw = SummaryWriter(log_dir=\"./tensorboard_logs/cnn/\" + comment + \"-\" + datetime.now().isoformat(sep='_'), \n",
    "                         comment=comment)\n",
    "    print(\"#\" * 80)\n",
    "    print(\"Training\", comment)\n",
    "\n",
    "    # Training loop\n",
    "    losses, accs, val_accs = train_class(\n",
    "        ARGS, model, \n",
    "        train_loader, val_loader,\n",
    "        optimizer, criterion,\n",
    "        device, tbsw\n",
    "    )\n",
    "    \n",
    "    # load best model and evaluate on test set\n",
    "    model.load_state_dict(torch.load(f'best_model.pt'))\n",
    "    test_loss, test_acc = evaluate_class(model, test_loader, criterion, device, tbsw, ARGS.epochs * len(train_loader) + 1)\n",
    "    print(f'Test loss={test_loss:.3f}; test accuracy={test_acc:.3f}')\n",
    "\n",
    "    # Copy model to unique filename\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    shutil.copyfile(\"best_model.pt\", f\"models/best_model-{comment}.pt\")\n",
    "    shutil.copyfile(\"last_model.pt\", f\"models/last_model-{comment}.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61d0dd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf, p = class_confusion(model, train_loader, math_class_map, device)\n",
    "plt.title(\"Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00cece69",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf, p = class_confusion(model, val_loader, math_class_map, device)\n",
    "plt.title(\"Validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49abcb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf, p = class_confusion(model, test_loader, math_class_map, device)\n",
    "plt.title(\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8de8e69",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class_prevalence(train_loader, math_class_map);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1bc645",
   "metadata": {},
   "source": [
    "# Generated Spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3258bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "genders = [\"female\", \"male\"]\n",
    "ages = [\"17\", \"18\", \"19\", \"20\", \"21\"]\n",
    "activities = [\"resting\", \"doing math\"]\n",
    "def make_prompt():\n",
    "    \"\"\"\n",
    "    | y | math? | gender |\n",
    "    |---|-------|--------|\n",
    "    | 0 |   0   |   0    |\n",
    "    | 1 |   0   |   1    |\n",
    "    | 2 |   1   |   0    |\n",
    "    | 3 |   1   |   1    |\n",
    "    \"\"\"\n",
    "    gender = np.random.choice(genders)\n",
    "    age = np.random.choice(ages)\n",
    "    activity = np.random.choice(activities)\n",
    "    prompt = f\"an EEG spectrogram of a {gender} {age} year old subject {activity}\"\n",
    "    y = (activity == \"doing math\") * 2 + (gender == \"female\")\n",
    "    return prompt, y\n",
    "\n",
    "def make_n_prompts(n):\n",
    "    for _ in range(n):\n",
    "        yield make_prompt()\n",
    "\n",
    "print(make_prompt())\n",
    "\n",
    "def im2tensor(image):\n",
    "    txfm = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.5], [0.5])\n",
    "            ])\n",
    "    return txfm(image.convert(\"L\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe9ea79",
   "metadata": {},
   "source": [
    "## Real-Trained Classifier on Generated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "29f88d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"../data/stft-full.eeg_math.1/\"\n",
    "# model_path = \"../data/stft-post-ft.eeg_math.0/\"\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_path, torch_dtype=torch.float16)\n",
    "pipe.to(\"cuda\")\n",
    "\n",
    "model = CNNClassifier(1, 4)\n",
    "model.load_state_dict(torch.load(f'best_model.pt'))\n",
    "model.to(\"cuda\")\n",
    "model.eval()\n",
    "model.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e7199faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_data = [(pipe(prompt, num_inference_steps=50, guidance_scale=7.5,).images[0], y)\n",
    "            for (prompt, y) in make_n_prompts(200)]\n",
    "print(gen_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "78c81400",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"gen_data.post-ft.pkl\", \"wb\") as f:\n",
    "    pickle.dump(gen_data, f)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9d971883",
   "metadata": {},
   "source": [
    "with open(\"gen_data.full-ft.pkl\", \"rb\") as f:\n",
    "with open(\"gen_data.post-ft.pkl\", \"rb\") as f:\n",
    "    gen_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d270496",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "22e6bf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_gen_data(classifier, gen_data,):\n",
    "    classifier.eval()\n",
    "    y_preds = []\n",
    "    ys = []\n",
    "    for (image, y) in gen_data:\n",
    "        input = im2tensor(image).to(\"cuda\")\n",
    "        yhat = classifier(input)\n",
    "        ys.append(y)\n",
    "        y_preds.append(torch.argmax(yhat).item())\n",
    "    return np.array(ys), np.array(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "673515bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ys, yhats = test_gen_data(model, gen_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a3db957a",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = sum(ys == yhats) / len(ys)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1e725751",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, fig = raw_class_confusion(ys, yhats)\n",
    "fig.gca().set_ylabel(\"Generator Prompted Class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "831162ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_class_prevalence(ys);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0557a4d",
   "metadata": {},
   "source": [
    "## Generative-Trained Classifier on Real Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b6bda0",
   "metadata": {},
   "source": [
    "### First, make a large dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caf45283",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"../data/stft-full.eeg_math.1/\"\n",
    "# model_path = \"../data/stft-post-ft.eeg_math.0/\"\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    model_path, \n",
    "    safety_checker=lambda images, **kwargs: (images, False),  # Disable safety checker - spectrograms won't be NSFW\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "pipe.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511c8e9f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "N = 1000\n",
    "batch = 8\n",
    "\n",
    "gendir = \"/data/shared/signal-diffusion/eeg_math/gen-stft/\"\n",
    "os.makedirs(gendir, exist_ok=True)\n",
    "\n",
    "files = []\n",
    "ys = []\n",
    "\n",
    "nn = (N + batch - 1) // batch\n",
    "for i in range(nn):\n",
    "    print(f\"Batch {i+1}/{nn}\")\n",
    "    prompts, yy = zip(*list(make_n_prompts(batch)))\n",
    "    ys.extend(yy)\n",
    "    images = pipe(list(prompts), num_inference_steps=50, guidance_scale=7.5,).images\n",
    "    for j in range(batch):\n",
    "        imname = f\"gen-{i * batch + j}.png\"\n",
    "        files.append(imname)\n",
    "        fname = os.path.join(gendir, imname)\n",
    "        images[j].convert(\"L\").save(fname)\n",
    "\n",
    "with open(\"metadata.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.write([\"file\", \"y\"])\n",
    "    for row in zip(files, ys):\n",
    "        writer.write(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afb7e3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
