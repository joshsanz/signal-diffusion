{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1200f947",
   "metadata": {},
   "source": [
    "# Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "798b6201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for Tensor\n",
    "import csv\n",
    "import itertools\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "from collections import OrderedDict\n",
    "from datetime import datetime\n",
    "from tempfile import TemporaryDirectory\n",
    "from typing import Tuple\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, Tensor\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import dataset\n",
    "\n",
    "sys.path.append(\"../common\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee09d60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.dog import DoG, LDoG, PDoG\n",
    "from models import TransformerClassifier, TransformerSequenceClassifier\n",
    "from common.eeg_datasets import EarDataset, EarEEGPreprocessor, MathDataset, MathPreprocessor\n",
    "from training import train_seq, train_class, evaluate_seq, evaluate_class, TrainingConfig\n",
    "from visualization import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ebe454",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls 'gdrive/My Drive/Muller Group Drive/Ear EEG/Drowsiness_Detection/classifier_TBME'\n",
    "# !ls C:\\Users\\arya_bastani\\Documents\\ear_eeg\\data\\ear_eeg_data\n",
    "ear_eeg_base_path = '/data/shared/signal-diffusion/'\n",
    "# ear_eeg_base_path = '/mnt/d/data/signal-diffusion/'\n",
    "ear_eeg_data_path = ear_eeg_base_path + 'eeg_classification_data/ear_eeg_data/ear_eeg_clean'\n",
    "math_data_path = '/data/shared/signal-diffusion/eeg_math/raw_eeg'\n",
    "# math_data_path = '/mnt/d/data/signal-diffusion/eeg_math/raw_eeg'\n",
    "%ls {ear_eeg_data_path}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "237c1f72",
   "metadata": {},
   "source": [
    "# Data Preprocessing (run once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2379a1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "preprocessor = EarEEGPreprocessor(ear_eeg_base_path,)\n",
    "\n",
    "seq_len = 2000\n",
    "# %time preprocessor.preprocess(seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101e161a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nsamps = 2000\n",
    "preprocessor = MathPreprocessor(math_data_path, nsamps)\n",
    "\n",
    "samps_per_file = 100\n",
    "# %time preprocessor.preprocess(samps_per_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b939eb8e",
   "metadata": {},
   "source": [
    "# Models and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317852fc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "d = MathDataset(math_data_path + \"/train\", 10)\n",
    "print(d[0][0].shape)\n",
    "print(d[0][1].shape)\n",
    "print(len(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196cef58",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "d = EarDataset(ear_eeg_base_path + \"ear_eeg_train\", 40)\n",
    "print(d[0][0].shape)\n",
    "print(d[0][1].shape)\n",
    "print(len(d))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6737589e",
   "metadata": {},
   "source": [
    "# Ear EEG Training"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d004de17",
   "metadata": {},
   "source": [
    "# Parameters\n",
    "BATCH_SIZE = 256\n",
    "SHUFFLE = True\n",
    "NUM_WORKERS = 8\n",
    "CONTEXT_SAMPS = 40\n",
    "\n",
    "# Datasets\n",
    "training_set = EarDataset(ear_eeg_base_path + \"ear_eeg_train\", CONTEXT_SAMPS)\n",
    "validation_set = EarDataset(ear_eeg_base_path + \"ear_eeg_val\", CONTEXT_SAMPS)\n",
    "test_set = EarDataset(ear_eeg_base_path + \"ear_eeg_test\", CONTEXT_SAMPS)\n",
    "training_generator = torch.utils.data.DataLoader(training_set, batch_size=BATCH_SIZE, \n",
    "                                                 shuffle=SHUFFLE, num_workers=NUM_WORKERS,\n",
    "                                                 pin_memory=True, persistent_workers=True)\n",
    "validation_generator = torch.utils.data.DataLoader(validation_set, batch_size=BATCH_SIZE, \n",
    "                                                   shuffle=SHUFFLE, num_workers=NUM_WORKERS,\n",
    "                                                   pin_memory=True, persistent_workers=True)\n",
    "test_generator = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE, \n",
    "                                             shuffle=SHUFFLE, num_workers=NUM_WORKERS,\n",
    "                                             pin_memory=True, persistent_workers=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f8fa191b",
   "metadata": {},
   "source": [
    "import time\n",
    "t0 = time.time()\n",
    "count = 0\n",
    "for i, (X, y) in enumerate(training_generator):\n",
    "    count = i\n",
    "    if i >= 100:\n",
    "        break\n",
    "t1 = time.time()\n",
    "print(f\"Achieved {(t1 - t0) / count} s/it\")\n",
    "print(\"or\")\n",
    "print(f\"Achieved {count / (t1 - t0)} it/s\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "01e608a2",
   "metadata": {},
   "source": [
    "# define hyperparameters\n",
    "INPUT_DIM = 10 * CONTEXT_SAMPS\n",
    "OUTPUT_DIM = 2\n",
    "HID_DIM = INPUT_DIM // 4\n",
    "N_LAYERS = 4\n",
    "N_HEADS = 4\n",
    "FF_DIM = 256\n",
    "DROPOUT = 0.1\n",
    "BATCH_FIRST = True # True: (batch, seq, feature). False: (seq, batch, feature)\n",
    "\n",
    "# CUDA for PyTorch\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "torch.backends.cudnn.benchmark = device.type == \"cuda\"\n",
    "\n",
    "# create model instance\n",
    "model = TransformerSequenceClassifier(INPUT_DIM, OUTPUT_DIM, HID_DIM, N_LAYERS, N_HEADS, FF_DIM, DROPOUT, BATCH_FIRST)\n",
    "model = model.to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = LDoG(model.parameters())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "415c4dfd",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# Log statistics\n",
    "tbsw = SummaryWriter(log_dir=\"./tensorboard_logs/\" + \"txfmr_seq_classifier-\" + datetime.now().isoformat(sep='_'), \n",
    "                     comment=f\"txfmr_seq_classifier_{type(optimizer)}\")\n",
    "\n",
    "# Training loop\n",
    "N_EPOCHS = 50\n",
    "losses, accs, val_accs = train_seq(\n",
    "    N_EPOCHS, model, \n",
    "    training_generator, validation_generator,\n",
    "    optimizer, criterion,\n",
    "    device, tbsw\n",
    ")\n",
    "\n",
    "# load best model and evaluate on test set\n",
    "model.load_state_dict(torch.load(f'best_model.pt'))\n",
    "test_loss, test_acc = evaluate_seq(model, test_generator, criterion, device, tbsw, N_EPOCHS * len(training_generator) + 1)\n",
    "print(f'Test loss={test_loss:.3f}; test accuracy={test_acc:.3f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4a626f06",
   "metadata": {},
   "source": [
    "# Math EEG Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b3d4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "BATCH_SIZE = 64\n",
    "SHUFFLE = True\n",
    "NUM_WORKERS = 1\n",
    "N_TOKENS = 128\n",
    "CONTEXT_SAMPS = 20\n",
    "N_SAMPS = CONTEXT_SAMPS * N_TOKENS\n",
    "persistent = NUM_WORKERS > 0\n",
    "\n",
    "# Datasets\n",
    "train_set = MathDataset(math_data_path + \"/train\", CONTEXT_SAMPS)\n",
    "val_set = MathDataset(math_data_path + \"/val\", CONTEXT_SAMPS)\n",
    "test_set = MathDataset(math_data_path + \"/test\", CONTEXT_SAMPS)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE, \n",
    "                                           shuffle=SHUFFLE, num_workers=NUM_WORKERS,\n",
    "                                           pin_memory=True, persistent_workers=persistent)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=BATCH_SIZE, \n",
    "                                         shuffle=SHUFFLE, num_workers=NUM_WORKERS,\n",
    "                                         pin_memory=True, persistent_workers=persistent)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE, \n",
    "                                          shuffle=SHUFFLE, num_workers=NUM_WORKERS,\n",
    "                                          pin_memory=True, persistent_workers=persistent)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "414ea53c",
   "metadata": {},
   "source": [
    "import time\n",
    "t0 = time.time()\n",
    "count = 0\n",
    "for i, (X, y) in enumerate(train_loader):\n",
    "    count = i\n",
    "    if i >= 100:\n",
    "        break\n",
    "t1 = time.time()\n",
    "print(f\"Achieved {(t1 - t0) / count} s/it\")\n",
    "print(\"or\")\n",
    "print(f\"Achieved {count / (t1 - t0)} it/s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787c1b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters\n",
    "INPUT_DIM = train_set.n_channels * CONTEXT_SAMPS\n",
    "OUTPUT_DIM = 4\n",
    "HID_DIM = INPUT_DIM\n",
    "N_LAYERS = 4\n",
    "N_HEADS = 4\n",
    "FF_DIM = 256\n",
    "DROPOUT = 0.1\n",
    "BATCH_FIRST = True # True: (batch, seq, feature). False: (seq, batch, feature)\n",
    "WEIGHT_DECAY = 0.0001\n",
    "\n",
    "# CUDA for PyTorch\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "torch.backends.cudnn.benchmark = device.type == \"cuda\"\n",
    "\n",
    "# create model instance\n",
    "model = TransformerClassifier(INPUT_DIM, OUTPUT_DIM, HID_DIM, N_LAYERS, N_HEADS, FF_DIM, DROPOUT, BATCH_FIRST)\n",
    "model = model.to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39683b1d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Runtime training parameters\n",
    "opt_options = [torch.optim.AdamW]\n",
    "decay_options = [0.00001]\n",
    "\n",
    "for opt, decay in itertools.product(opt_options, decay_options):\n",
    "    # Create model instance\n",
    "    model = TransformerClassifier(INPUT_DIM, OUTPUT_DIM, HID_DIM, N_LAYERS, N_HEADS, FF_DIM, DROPOUT, BATCH_FIRST)\n",
    "    model = model.to(device)\n",
    "    optimizer = opt(model.parameters(), lr=1e-3, weight_decay=decay)\n",
    "    ARGS = TrainingConfig(epochs=300, val_every_epochs=10)\n",
    "\n",
    "    # Log statistics\n",
    "    postfix = \"\"\n",
    "    comment = f\"txfmclass_{str(type(optimizer)).split('.')[-1][:-2]}_decay{decay}{postfix}\"\n",
    "    tbsw = SummaryWriter(log_dir=\"./tensorboard_logs/\" + comment + \"-\" + datetime.now().isoformat(sep='_'),\n",
    "                         comment=comment)\n",
    "    print(\"#\" * 80)\n",
    "    print(\"Training\", comment)\n",
    "\n",
    "    # Training loop\n",
    "    losses, accs, val_accs = train_class(\n",
    "        ARGS, model,\n",
    "        train_loader, val_loader,\n",
    "        optimizer, criterion,\n",
    "        device, tbsw\n",
    "    )\n",
    "\n",
    "    # load best model and evaluate on test set\n",
    "    model.load_state_dict(torch.load(f'best_model.pt'))\n",
    "    test_loss, test_acc = evaluate_class(model, test_loader, criterion, device, tbsw, ARGS.epochs * len(train_loader) + 1)\n",
    "    print(f'Test loss={test_loss:.3f}; test accuracy={test_acc:.3f}')\n",
    "\n",
    "    # Copy model to unique filename\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    shutil.copyfile(\"best_model.pt\", f\"models/best_model-{comment}.pt\")\n",
    "    shutil.copyfile(\"last_model.pt\", f\"models/last_model-{comment}.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d0dd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf, p = class_confusion(model, train_loader, math_class_map, device)\n",
    "plt.title(\"Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cece69",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf, p = class_confusion(model, val_loader, math_class_map, device)\n",
    "plt.title(\"Validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49abcb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf, p = class_confusion(model, test_loader, math_class_map, device)\n",
    "plt.title(\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8de8e69",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class_prevalence(train_loader, math_class_map);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54b6ec5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
