{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "798b6201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Imports for Tensor\n",
    "import math\n",
    "import os\n",
    "from tempfile import TemporaryDirectory\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68ebe454",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls 'gdrive/My Drive/Muller Group Drive/Ear EEG/Drowsiness_Detection/classifier_TBME'\n",
    "#!ls C:\\Users\\arya_bastani\\Documents\\ear_eeg\\data\\ear_eeg_data\n",
    "ear_eeg_data_path = '/data/shared/signal-diffusion/eeg_classification_data/ear_eeg_data/ear_eeg_clean'\n",
    "\n",
    "%ls {ear_eeg_data_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c9432ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "\n",
    "#import support scripts: pull_data\n",
    "import support_scripts.read_in_ear_eeg as read_in_ear_eeg\n",
    "import support_scripts.read_in_labels as read_in_labels\n",
    "import support_scripts.eeg_filter as eeg_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2d06940",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# READ-IN EAR EEG\n",
    "##################\n",
    "# NOTE, this takes a long time to run.\n",
    "# (It could be parallelized to reduce runtime)\n",
    "\n",
    "# name of spreadsheet with experiment details\n",
    "# details_spreadsheet = 'gdrive/My Drive/Muller Group Drive/Ear EEG/Drowsiness_Detection/classifier_TBME/classification_scripts/trial_details_spreadsheet_basic.csv'\n",
    "details_spreadsheet = r'/data/shared/signal-diffusion/eeg_classification_data/ear_eeg_data/trial_details_spreadsheet_good.csv'\n",
    "\n",
    "# file path to ear eeg data (must be formated r'filepath\\\\')\n",
    "#data_filepath = r'C:\\Users\\Carolyn\\OneDrive\\Documents\\school\\berkeley\\research\\ear_eeg_classification_framework\\experimental_recordings\\drowsiness_studies\\ear_eeg\\\\'\n",
    "data_filepath = r'/data/shared/signal-diffusion/eeg_classification_data/ear_eeg_data/ear_eeg_clean//'\n",
    "\n",
    "# user number or all users('all', 'ryan', 'justin', 'carolyn', 'ashwin', 'connor')\n",
    "input_users = 'all'\n",
    "\n",
    "# channels of eeg to read in for each trial (must include 5 and 11 if re-refernecing is enabled in the next block)\n",
    "data_chs = [1,2,3,4,5,7,8,9,10,11]\n",
    "\n",
    "# sampling frequency of system (fs=1000 for wandmini)\n",
    "fs = 1000\n",
    "\n",
    "# plot eeg data that is read in\n",
    "plot_raw_data_enable = False\n",
    "\n",
    "# call read in ear eeg\n",
    "all_raw_data, filenames, data_lengths, file_users, refs = read_in_ear_eeg.read_in_clean_data(details_spreadsheet, data_filepath, input_users, data_chs, fs, plot_raw_data_enable)\n",
    "#all_raw_data = np.array(all_raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d63f0997",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_raw_data[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "510b7c84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#################\n",
    "# READ-IN LABELS\n",
    "#################\n",
    "\n",
    "# Note: label read in will match Ear EEG read in\n",
    "# (same trials will be read in, and the experiment lengths will be the same)\n",
    "\n",
    "# file path to labels(must be formated r'filepath\\\\')\n",
    "#label_filepath = r'C:\\Users\\Carolyn\\OneDrive\\Documents\\school\\berkeley\\research\\ear_eeg_classification_framework\\experimental_recordings\\drowsiness_studies\\labels\\\\'\n",
    "label_filepath =  r'/data/shared/signal-diffusion/eeg_classification_data/ear_eeg_data/labels//'\n",
    "\n",
    "# plot the labels that are read in\n",
    "plot_labels_enable = False\n",
    "\n",
    "# call read in labels\n",
    "all_labels = read_in_labels.read_in_labels(filenames, data_lengths, label_filepath, plot_labels_enable)\n",
    "all_labels = np.array(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "003fc58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_labels[21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d665100",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = eeg_filter.filter_studies(all_raw_data)\n",
    "\n",
    "\n",
    "print(len(all_raw_data))\n",
    "print(all_raw_data[0].shape)\n",
    "\n",
    "print(len(filtered_data))\n",
    "print(filtered_data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6da2598c",
   "metadata": {},
   "outputs": [],
   "source": [
    "del all_raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1185545e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data constants\n",
    "carolyn_indices = [0,1,2,3,4]\n",
    "ryan_indices = [5,6,7,8,9]\n",
    "justin_indices = [10,11,12,13,14]\n",
    "conor_indices = [15,16,17,18,19]\n",
    "avi_indices = [20,21]\n",
    "train_perc, val_perc, test_perc = 0.55, 0.30, .15\n",
    "train_ind = [2,3,4,8,9,12,13,14,15,17,18,19,21]\n",
    "val_ind = [1,6,11,16,20,7]\n",
    "test_ind = [0,5,10]\n",
    "\n",
    "# Model Constants\n",
    "window_size = 10 # Seconds\n",
    "sample_rate = 1000 # Hertz\n",
    "\n",
    "# Model Params\n",
    "seq_size = window_size * sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38c58005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split up into train, val, and test datasets\n",
    "train_data, val_data, test_data = [],[],[]\n",
    "train_labels, val_labels, test_labels = [],[],[]\n",
    "\n",
    "\n",
    "for i in range(len(filtered_data)):\n",
    "    if i in train_ind:\n",
    "        train_data.append(filtered_data[i])\n",
    "        train_labels.append(all_labels[i])\n",
    "    elif i in val_ind:\n",
    "        val_data.append(filtered_data[i])\n",
    "        val_labels.append(all_labels[i])\n",
    "    else:\n",
    "        test_data.append(filtered_data[i])\n",
    "        test_labels.append(all_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62056e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data[0].T[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02718772",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatt_data(data_set, seq_len):\n",
    "    # Data needs to be input as (samples, channels), for ex: (2,400,000, 10)\n",
    "    new_dataset = []\n",
    "    for data in data_set:\n",
    "        data = data.T\n",
    "        #print(data.shape)\n",
    "        new_data = []\n",
    "        row_len = data.shape[1]\n",
    "\n",
    "        num_seqs = int(row_len/seq_len)\n",
    "        for row in data:\n",
    "            #print(num_seqs)\n",
    "            new_row = np.split(row, num_seqs)\n",
    "            new_data.append(new_row)\n",
    "            #print(\"bad\")\n",
    "        new_data = np.array(new_data).T\n",
    "        #print(new_data.shape)\n",
    "        new_dataset.append(new_data)\n",
    "        \n",
    "    return new_dataset\n",
    "\n",
    "def one_hot_encode(input):\n",
    "    one_hot_formatted_seq_labels = []\n",
    "    b = np.zeros((int(input.size), int(input.max() + 1)))\n",
    "    b[np.arange(input.size), input] = 1\n",
    "    one_hot_labels = np.array(b)\n",
    "\n",
    "    return one_hot_labels\n",
    "\n",
    "def formatt_labels(labels_set, seq_size):\n",
    "    processed_labels = []\n",
    "    for i in range(len(labels_set)):\n",
    "        old_one_hot_labels = one_hot_encode(train_labels[i])\n",
    "        new_labels = old_one_hot_labels[::seq_size]    \n",
    "        processed_labels.append(new_labels)\n",
    "    return processed_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dea84fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(train_data).shape)\n",
    "print(np.array(train_data).T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0bfcb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_train = formatt_data(train_data, seq_size)\n",
    "proc_val = formatt_data(val_data, seq_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0f94b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(proc_train[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd84720a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# format the labels\n",
    "processed_train_labels = formatt_labels(train_labels, seq_size)\n",
    "processed_val_labels = formatt_labels(val_labels, seq_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2bac743e",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train_labels[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0bb9541e",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_train_new = [study[::4] for study in proc_train]\n",
    "processed_train_labels_new = [study[::4] for study in processed_train_labels]\n",
    "\n",
    "proc_val_new = [study[::4] for study in proc_val]\n",
    "processed_val_labels_new = [study[::4] for study in processed_val_labels]\n",
    "\n",
    "print(proc_train_new[0].shape)\n",
    "\n",
    "print(processed_train_labels_new[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "286553c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_train_new = [study[:400] for study in proc_train_new]\n",
    "\n",
    "proc_val_new = [study[:400] for study in proc_val_new]\n",
    "\n",
    "print(proc_train_new[0].shape)\n",
    "\n",
    "print(processed_train_labels_new[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "565c84e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable \n",
    "\n",
    "# Turn into tensors\n",
    "\n",
    "X_train_tensors = [torch.from_numpy(batch) for batch in proc_train_new]\n",
    "y_train_tensors = [torch.from_numpy(batch) for batch in processed_train_labels_new]\n",
    "\n",
    "X_val_tensors = [torch.from_numpy(batch) for batch in proc_val_new]\n",
    "y_val_tensors = [torch.from_numpy(batch) for batch in processed_val_labels_new]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8c69b3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_tensors[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71c772a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding Layer\n",
    "# In this implementation we will do a sort of raw embedding for the system\n",
    "# We will treat each channel as a word, and define the length of each word as the window size we are referencing\n",
    "# The vectors of each channel will be strung together in order to make a \"sentence\" which will then have positional \n",
    "# encoding added to it, and from there we'll pass it into the \n",
    "\n",
    "\"\"\"\n",
    "class AryaEmbed():\n",
    "    def __init__(vect_len: int):\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ac42dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        print(\"sdapoasd\")\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        #Args:\n",
    "        #    x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "        \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "085ff5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGTransformerModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0.1, \n",
    "                 layer_norm_eps=1e-05, batch_first=False, norm_first=False, device=None, dtype=None):\n",
    "        super().__init__()\n",
    "\n",
    "        print(nhead)\n",
    "        \n",
    "        # d_model = number input feature\n",
    "        self.model_type = 'Transformer'\n",
    "        #self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        # batch_first = False -> (seq, batch, feat, batch_first = True -> (batch, seq, feat)\n",
    "        self.transformer = torch.nn.TransformerEncoderLayer(d_model, nhead, dim_feedforward=dim_feedforward, \n",
    "                                                      dropout=dropout, layer_norm_eps=layer_norm_eps, \n",
    "                                                      batch_first=batch_first, norm_first=norm_first, \n",
    "                                                      device=device, dtype=dtype)\n",
    "            \n",
    "        self.fc1 = nn.Linear(d_model, 2)\n",
    "        self.softy = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    def forward(self, src):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            src: Tensor, shape [seq_len, batch_size]\n",
    "            src_mask: Tensor, shape [seq_len, seq_len]\n",
    "\n",
    "        Returns:\n",
    "            output Tensor of shape [seq_len, batch_size, ntoken]\n",
    "        \"\"\"\n",
    "        #src = self.pos_encoder(src)\n",
    "        print(\"OG src shape: \", src.shape)\n",
    "            \n",
    "        \n",
    "        #src = np.concatenate((src, src,src,src,src,src))\n",
    "        src = src.float() #solved the mat1 and mat2 need to be the same dtype error\n",
    "\n",
    "        print(\"NEW src shape: \", src.shape)\n",
    "        print(\"NEW src dtype: \", src.dtype)\n",
    "\n",
    "        \n",
    "        trans_output1 = self.transformer(src)\n",
    "        trans_output2 = self.transformer(trans_output1)\n",
    "        trans_output3 = self.transformer(trans_output2)\n",
    "        trans_output4 = self.transformer(trans_output3)\n",
    "\n",
    "        # should I add a ReLU here?\n",
    "        lin_output = self.fc1(trans_output4)\n",
    "        print(lin_output.shape)\n",
    "        output = self.softy(lin_output)\n",
    "        print(output.shape)\n",
    "        \n",
    "        return output\n",
    "print('good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7783aaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "dmodel = 10000   #  10 channels, 10 feats\n",
    "nhead = 10\n",
    "num_encoder_layers = 4\n",
    "dropout = 0.1\n",
    "\n",
    "bumblebrain = EEGTransformerModel(dmodel, nhead, batch_first=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfded8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dmodel = 10   #  10 channels, 10 feats\n",
    "nhead = 10\n",
    "batch_first = False \n",
    "num_encoder_layers = 4\n",
    "dropout = 0.1\n",
    "\n",
    "bumblebrain = EEGTransformerModel(dmodel, nhead, batch_first=batch_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ad2d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### THIS IS WHERE THE TRANSFORMER TRAINSSS!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cff275",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.metrics import accuracy_score\n",
    "\n",
    "epochs = 1\n",
    "optimizer = torch.optim.SGD(bumblebrain.parameters(),lr=0.1)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "\n",
    "epoch_loss = []\n",
    "epoch_acc = []\n",
    "for epoch in range(epochs):\n",
    "    print(epoch)\n",
    "    total_loss = 0\n",
    "    loss_avg = 0\n",
    "    \n",
    "    total_acc = 0\n",
    "    acc_avg = 0\n",
    "    \n",
    "    for i in range(len(X_train_tensors)):\n",
    "        X_train = X_train_tensors[i]\n",
    "        y_train = y_train_tensors[i]\n",
    "        \n",
    "        train_pred = bumblebrain.forward(X_train)\n",
    "        \n",
    "        train_loss = criterion(train_pred, y_train)\n",
    "        #train_acc = accuracy_score(train_pred, y_train()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += train_loss\n",
    "        loss_avg += 1\n",
    "        total_acc += train_acc\n",
    "    \n",
    "    epoch_loss.append(total_loss/loss_avg)\n",
    "    epoch_acc.append(total_acc/loss_avg)\n",
    "        \n",
    "    for i in range(len(X_val_tensors)):\n",
    "        X_val = X_val_tensors[i]\n",
    "        y_val = y_val_tensors[i]\n",
    "        \n",
    "        val_pred = bumblebrain.forward(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c08fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff8638a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_tensors.shape)\n",
    "  train_pred = lstm.forward(X_train_tensors) #forward pass\n",
    "  print(\"pre soft train_pred: \", train_pred.shape)\n",
    "  softmaxed_train_pred = train_pred.argmax(dim=2,keepdim=False)\n",
    "  print(\"post soft train_pred: \", softmaxed_train_pred.shape)\n",
    "\n",
    "\n",
    "\n",
    "  optimizer.zero_grad() #caluclate the gradient, manually setting to 0\n",
    "\n",
    "  #print(type(train_pred[0][0][0]))\n",
    "  #print(type(y_train_tensors[0][0][0]))\n",
    "\n",
    "  print(train_pred.shape)\n",
    "  print(y_train_tensors.shape)\n",
    "\n",
    "\n",
    "  train_loss = criterion(train_pred, y_train_tensors)\n",
    "  train_loss.backward() #calculates the loss of the loss function\n",
    "  optimizer.step() #improve from loss, i.e backprop\n",
    "\n",
    "\n",
    "  # Run on validation\n",
    "  test_pred = lstm.forward(X_test_tensors) #forward pass\n",
    "  #test_loss = criterion(test_pred.type(torch.LongTensor), y_test_tensors.type(torch.LongTensor))\n",
    "  test_loss = criterion(test_pred, y_test_tensors)\n",
    "\n",
    "  softmaxed_test_pred = test_pred.argmax(dim=2,keepdim=False)\n",
    "\n",
    "\n",
    "  print(\"softmaxed_train_pred; \", softmaxed_train_pred.shape)\n",
    "  print(\"y_train: \", y_train.shape)\n",
    "\n",
    "\n",
    "  train_accuracy = accuracy_score(softmaxed_train_pred, y_train)\n",
    "  train_accuracies.append(train_accuracy)\n",
    "  train_losses.append(train_loss.item())\n",
    "\n",
    "  test_accuracy = accuracy_score(softmaxed_test_pred, y_test)\n",
    "  test_accuracies.append(test_accuracy)\n",
    "  test_losses.append(test_loss.item())\n",
    "\n",
    "  #test_sensitivity, test_specificity = sensitivy_specificity_results(softmaxed_test_pred, y_test, False)\n",
    "  #test_sensitivities.append(test_sensitivity)\n",
    "  #test_specificities.append(test_specificity)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b54e3ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afef27fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2684022c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### TEST SECTION #######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7542d5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_data = []\n",
    "for i in range(10):\n",
    "    start_val = 100000*i\n",
    "    end_val = start_val + 11000\n",
    "    row = np.arange(start_val, end_val)\n",
    "    fake_data.append(row)\n",
    "fake_data = np.array(fake_data)\n",
    "\n",
    "print(fake_data.shape)\n",
    "print(fake_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1c3c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_size = 1000\n",
    "num_seqs = 10\n",
    "#new_fake = np.reshape(fake_data, (10,num_seqs, seq_size))\n",
    "\n",
    "\n",
    "new_fake = []\n",
    "for row in fake_data:\n",
    "    new_row = np.split(row,11)\n",
    "    new_fake.append(new_row)\n",
    "    \n",
    "new_fake = np.array(new_fake)  \n",
    "\n",
    "\n",
    "print(new_fake.shape)\n",
    "print(new_fake)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
