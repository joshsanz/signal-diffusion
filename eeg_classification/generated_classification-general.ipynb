{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74eecc2b",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "798b6201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for Tensor\n",
    "import csv\n",
    "import itertools\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import sys\n",
    "from collections import OrderedDict\n",
    "from datetime import datetime\n",
    "from tempfile import TemporaryDirectory\n",
    "from typing import Tuple\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, Tensor\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import dataset\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from datasets import load_dataset\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b2f670f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.dog import DoG, LDoG, PDoG\n",
    "from cnn_models import model_size\n",
    "from cnn_models import CNNClassifier, CNNClassifierLight\n",
    "from cnn_models import EfficientNet, ShuffleNet, ResNet\n",
    "from data_processing.math import MathDataset\n",
    "from data_processing.parkinsons import ParkinsonsDataset\n",
    "from data_processing.seed import SEEDDataset\n",
    "from data_processing.general_dataset import GeneralPreprocessor, GeneralDataset, GeneralSampler\n",
    "from data_processing.general_dataset import general_class_labels, general_dataset_map\n",
    "from training import train_class, evaluate_class, TrainingConfig, LabelSmoothingCrossEntropy\n",
    "from visualization import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfe9bf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 205 #205 Gave a good split for training\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68ebe454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datapaths\n",
    "datadirs = {}\n",
    "# datahome = '/data/shared/signal-diffusion'\n",
    "datahome = '/mnt/d/data/signal-diffusion'\n",
    "\n",
    "\n",
    "# Math dataset\n",
    "datadirs['math'] = f'{datahome}/eeg_math'\n",
    "datadirs['math-stft'] = os.path.join(datadirs['math'], 'stfts')\n",
    "\n",
    "# Parkinsons dataset\n",
    "datadirs['parkinsons'] = f'{datahome}/parkinsons/'\n",
    "datadirs['parkinsons-stft'] = os.path.join(datadirs['parkinsons'], 'stfts')\n",
    "\n",
    "#SEED dataset\n",
    "datadirs['seed'] = f'{datahome}/seed/'\n",
    "datadirs['seed-stft'] = os.path.join(datadirs['seed'], \"stfts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237c1f72",
   "metadata": {},
   "source": [
    "# Data Preprocessing (run once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "101e161a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nsamps = 2000\n",
    "\n",
    "preprocessor = GeneralPreprocessor(datadirs, nsamps, ovr_perc=0.5, fs=125) \n",
    "#preprocessor.preprocess(resolution=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "facbf80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# math_subs = list(math_train_subs.loc[:,\"subject\"])\n",
    "# math_m, math_f = 0, 0\n",
    "# for sub in math_subs:\n",
    "#     ind = int(sub[-2:])\n",
    "#     gen = math_train_info.iloc[ind][2]\n",
    "#     if gen == \"F\":\n",
    "#         math_f += 1\n",
    "#     else:\n",
    "#         math_m += 1\n",
    "        \n",
    "# park_m = park_df.gender[park_df[\"gender\"] == \"M\"].count()\n",
    "# park_f = park_df.gender[park_df[\"gender\"] == \"F\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38b202c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_math = math_m + math_f\n",
    "# total_park = park_m + park_f\n",
    "\n",
    "# print(total_math, total_park)\n",
    "# print(total_math / (total_math + total_park))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba340e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_m = math_m + park_m\n",
    "# total_f = math_f + park_f\n",
    "\n",
    "# # Male female breakdown\n",
    "# print(total_m, total_f)\n",
    "# print(total_m / (total_m + total_f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b939eb8e",
   "metadata": {},
   "source": [
    "# Models and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e17bc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load Individual Datasets\n",
    "# math_dataset = MathSpectrumDataset(datadirs['math'] + \"/train\", resolution=256)\n",
    "# parkinsons_dataset = ParkinsonsDataset(datadirs['parkinsons-stft'], split=\"train\")\n",
    "\n",
    "# datasets = [math_dataset, math_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "317852fc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# d = GeneralDataset(datasets, split=\"train\")\n",
    "# print(d[0][0].shape)\n",
    "# print(d[0][1])\n",
    "# print(len(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "989d8f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dl = torch.utils.data.DataLoader(d, batch_size=16, shuffle=True,)\n",
    "# S, y = next(iter(dl))\n",
    "# print(S.shape, y.shape)\n",
    "# print(S.max(), S.min(), S.mean(), S.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85df8b3f",
   "metadata": {},
   "source": [
    "# Train on Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df58b7a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "BATCH_SIZE = 32\n",
    "SHUFFLE = True\n",
    "NUM_WORKERS = 16\n",
    "N_TOKENS = 128\n",
    "RESOLUTION = 256\n",
    "HOP_LENGTH = 80\n",
    "persistent = NUM_WORKERS > 0\n",
    "\n",
    "# Data augmentation\n",
    "randtxfm = transforms.Compose([\n",
    "    transforms.TrivialAugmentWide(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5]),\n",
    "])\n",
    "\n",
    "# Datasets\n",
    "# train_set = GeneratedSpectrumDataset(gendir)\n",
    "math_val_dataset = MathDataset(datadirs['math-stft'], split=\"val\")\n",
    "parkinsons_val_dataset = ParkinsonsDataset(datadirs['parkinsons-stft'], split=\"val\")\n",
    "seed_val_dataset = SEEDDataset(datadirs['seed-stft'], split=\"val\")\n",
    "# val_datasets = [math_val_dataset, parkinsons_val_dataset, seed_val_dataset]\n",
    "\n",
    "val_datasets = [parkinsons_val_dataset, seed_val_dataset]\n",
    "\n",
    "math_test_dataset = MathDataset(datadirs['math-stft'], split=\"test\")\n",
    "parkinsons_test_dataset = ParkinsonsDataset(datadirs['parkinsons-stft'], split=\"test\")\n",
    "seed_test_dataset = SEEDDataset(datadirs['seed-stft'], split=\"test\")\n",
    "# test_datasets = [math_test_dataset, parkinsons_test_dataset, seed_test_dataset]\n",
    "test_datasets = [parkinsons_test_dataset, seed_test_dataset]\n",
    "\n",
    "math_real_train_dataset = MathDataset(datadirs['math-stft'], split=\"train\")\n",
    "parkinsons_real_train_dataset = ParkinsonsDataset(datadirs['parkinsons-stft'], split=\"train\", transform=None)\n",
    "seed_real_train_dataset = SEEDDataset(datadirs['seed-stft'], split=\"train\")\n",
    "\n",
    "# real_train_datasets = [math_real_train_dataset, parkinsons_real_train_dataset, seed_real_train_dataset]\n",
    "real_train_datasets = [parkinsons_real_train_dataset, seed_real_train_dataset]\n",
    "\n",
    "\n",
    "val_set = GeneralDataset(val_datasets, split='val')\n",
    "test_set = GeneralDataset(test_datasets, split='test')\n",
    "real_train_set = GeneralDataset(real_train_datasets, split='train')\n",
    "\n",
    "train_samp = GeneralSampler(real_train_datasets, BATCH_SIZE, split='train')\n",
    "# val_samp = ParkinsonsSampler(stft_path, BATCH_SIZE, split='val')\n",
    "# test_samp = ParkinsonsSampler(stft_path, BATCH_SIZE, split='test')\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=SHUFFLE,\n",
    "                                         num_workers=NUM_WORKERS, pin_memory=True, \n",
    "                                         persistent_workers=persistent)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=SHUFFLE,\n",
    "                                          num_workers=NUM_WORKERS, pin_memory=True, \n",
    "                                          persistent_workers=persistent)\n",
    "# real_train_loader = torch.utils.data.DataLoader(real_train_set, batch_size=BATCH_SIZE, shuffle=SHUFFLE,\n",
    "#                                                 num_workers=NUM_WORKERS, pin_memory=True, \n",
    "#                                                 persistent_workers=persistent)\n",
    "\n",
    "real_train_loader = torch.utils.data.DataLoader(real_train_set, batch_size=BATCH_SIZE, \n",
    "                                                num_workers=NUM_WORKERS, pin_memory=True, \n",
    "                                                persistent_workers=persistent, sampler=train_samp)\n",
    "\n",
    "# val_loader = torch.utils.data.DataLoader(val_set, batch_size=BATCH_SIZE, \n",
    "#                                          num_workers=NUM_WORKERS, pin_memory=True, \n",
    "#                                          persistent_workers=persistent, sampler=val_samp)\n",
    "# test_loader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE,\n",
    "#                                           num_workers=NUM_WORKERS, pin_memory=True, \n",
    "#                                           persistent_workers=persistent, sampler=test_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eabb862",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d6f5b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters\n",
    "OUTPUT_DIM = 2\n",
    "DROPOUT = 0.5\n",
    "BATCH_FIRST = True # True: (batch, seq, feature). False: (seq, batch, feature)\n",
    "\n",
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Loss function\n",
    "criterion = LabelSmoothingCrossEntropy(epsilon=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a69d5fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNClassifierLight(in_channels=1, out_dim=OUTPUT_DIM, dropout=DROPOUT, pooling=\"max\")\n",
    "y = model(torch.randn(1, 1, 256, 256))\n",
    "model_size(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4af3e640",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Runtime training parameters\n",
    "opt, decay, restart, max_eta, decouple = (torch.optim.AdamW, 0.05, 0, None, True)\n",
    "\n",
    "for decay in [0.001,]:\n",
    "    # Create model instance\n",
    "    model = CNNClassifierLight(1, OUTPUT_DIM, dropout=DROPOUT,pooling=\"max\")\n",
    "    model = model.to(device)    \n",
    "    if opt == torch.optim.AdamW:\n",
    "        optimizer = opt(model.parameters(), lr=1e-3, weight_decay=decay)\n",
    "    else:\n",
    "        optimizer = opt(model.parameters(), weight_decay=decay, max_eta=max_eta, \n",
    "                        decouple_weight_decay=decouple)\n",
    "\n",
    "    # Create training configuration\n",
    "    ARGS = TrainingConfig(epochs=1, val_every_epochs=8, opt_restart_every=restart)\n",
    "\n",
    "    # Log statistics\n",
    "    postfix = \"\"\n",
    "    if isinstance(optimizer, DoG):\n",
    "        postfix = f\"_restart{restart}_etamax{max_eta}_decouple{str(int(decouple))}\"\n",
    "    comment = f\"cnnclass_{str(type(optimizer)).split('.')[-1][:-2]}_decay{decay}{postfix}\"\n",
    "    tbsw = SummaryWriter(log_dir=\"./tensorboard_logs/cnn/\" + comment + \"-\" + \n",
    "                         datetime.now().isoformat(sep='_'), \n",
    "                         comment=comment)\n",
    "    print(\"#\" * 80)\n",
    "    print(\"Training\", comment)\n",
    "\n",
    "    # Training loop\n",
    "    losses, accs, val_accs = train_class(\n",
    "        ARGS, model, \n",
    "        real_train_loader, val_loader,\n",
    "        optimizer, criterion,\n",
    "        device, tbsw\n",
    "    )\n",
    "\n",
    "    # load best model and evaluate on test set\n",
    "    model.load_state_dict(torch.load(f'best_model.pt'))\n",
    "    test_loss, test_acc = evaluate_class(model, test_loader, criterion, device, \n",
    "                                         tbsw, ARGS.epochs * len(real_train_loader) + 1)\n",
    "    print(f'Test loss={test_loss:.3f}; test accuracy={test_acc:.3f}')\n",
    "\n",
    "    # Copy model to unique filename\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    shutil.copyfile(\"best_model.pt\", f\"models/best_model-{comment}.pt\")\n",
    "    shutil.copyfile(\"last_model.pt\", f\"models/last_model-{comment}.pt\")\n",
    "    print(f\"Copied best model to models/best_model-{comment}.pt\")\n",
    "\n",
    "rmodel = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "434c7b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_prevalence(real_train_loader, general_class_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "596421ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vs_epoch(losses, accs, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f620cd7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cf, p = class_confusion(rmodel, real_train_loader, general_class_labels, device)\n",
    "plt.title(\"MAIN Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff2519f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf, p = class_confusion(rmodel, val_loader, general_class_labels, device)\n",
    "plt.title(\"Validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb502b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf, p = class_confusion(rmodel, test_loader, general_class_labels, device)\n",
    "plt.title(\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b279aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in real_train_datasets:\n",
    "    real_train_set = GeneralDataset([dataset], split='train')\n",
    "\n",
    "    real_train_loader = torch.utils.data.DataLoader(real_train_set, batch_size=BATCH_SIZE, shuffle=SHUFFLE,\n",
    "                                                num_workers=NUM_WORKERS, pin_memory=True, \n",
    "                                                persistent_workers=persistent)\n",
    "    \n",
    "    \n",
    "    train_loss, train_acc = evaluate_class(model, real_train_loader, criterion, device, \n",
    "                                     tbsw, ARGS.epochs * len(real_train_loader) + 1)\n",
    "    cf, p = class_confusion(rmodel, real_train_loader, general_class_labels, device)\n",
    "    plt.title(\"Train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e3478ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in val_datasets:\n",
    "    test_set = GeneralDataset([dataset], split='val')\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=SHUFFLE,\n",
    "                                                num_workers=NUM_WORKERS, pin_memory=True, \n",
    "                                                persistent_workers=persistent)\n",
    "    test_loss, test_acc = evaluate_class(model, test_loader, criterion, device, \n",
    "                                     tbsw, ARGS.epochs * len(real_train_loader) + 1)\n",
    "    print(f'Val loss={test_loss:.3f}; Val accuracy={test_acc:.3f}')\n",
    "    cf, p = class_confusion(rmodel, test_loader, general_class_labels, device)\n",
    "    plt.title(\"Validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9fdb4e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in test_datasets:\n",
    "    test_set = GeneralDataset([dataset], split='test')\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=SHUFFLE,\n",
    "                                                num_workers=NUM_WORKERS, pin_memory=True, \n",
    "                                                persistent_workers=persistent)\n",
    "    \n",
    "    test_loss, test_acc = evaluate_class(model, test_loader, criterion, device, \n",
    "                                     tbsw, ARGS.epochs * len(real_train_loader) + 1)\n",
    "    print(f'Test loss={test_loss:.3f}; test accuracy={test_acc:.3f}')\n",
    "    cf, p = class_confusion(rmodel, test_loader, general_class_labels, device)\n",
    "    plt.title(\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae6ce888",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_prevalence(real_train_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a147be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_prevalence(val_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d9eb1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_prevalence(test_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f7531f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_prevalence(real_train_datasets, general_dataset_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1eafe4b4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class_prevalence(real_train_loader, general_class_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b4cfe2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_prevalence(val_loader, general_class_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f574a176",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_prevalence(val_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "56540802",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_prevalence(test_loader, general_class_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d21a224",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b446dd8b",
   "metadata": {},
   "source": [
    "# Generate a fake dataset"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3fde18d8",
   "metadata": {},
   "source": [
    "genders = [\"female\", \"male\"]\n",
    "ages = np.arange(60, 80)\n",
    "healths = [\"healthy\", \"parkinsons disease diagnosed\"]\n",
    "def make_prompt():\n",
    "    gender = np.random.choice(genders, p=[.33, .67])\n",
    "    age = np.random.choice(ages)\n",
    "    health = np.random.choice(healths, p=[.33, .67])\n",
    "    prompt = f\"an EEG spectrogram of a {age} year old, {health}, {gender} subject\"\n",
    "    y = (health != \"healthy\") * 2 + (gender == \"female\")\n",
    "    return prompt, y\n",
    "\n",
    "def make_n_prompts(n):\n",
    "    for _ in range(n):\n",
    "        yield make_prompt()\n",
    "\n",
    "print(make_prompt())\n",
    "\n",
    "def im2tensor(image):\n",
    "    txfm = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.5], [0.5])\n",
    "            ])\n",
    "    return txfm(image.convert(\"L\"))\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f7fe9b30",
   "metadata": {},
   "source": [
    "model_path = \"../data/stft-full.parkinsons.0/\"\n",
    "# model_path = \"../data/stft-post-ft.parkinsons.0/\"\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    model_path, \n",
    "    safety_checker=lambda images, **kwargs: (images, False),  # Disable safety checker - spectrograms won't be NSFW\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "pipe.set_progress_bar_config(disable=True)\n",
    "pipe.to(\"cuda\")\n",
    "\n",
    "# model = CNNClassifier(1, 4)\n",
    "# model.load_state_dict(torch.load(f'best_model.pt'))\n",
    "# model.to(\"cuda\")\n",
    "# model.eval()\n",
    "# model.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5ab2bcc9",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "N = 5000\n",
    "batch = 8\n",
    "offset = 0\n",
    "\n",
    "gendir = \"/data/shared/signal-diffusion/parkinsons/gen-stft.1/\"\n",
    "os.makedirs(gendir, exist_ok=True)\n",
    "\n",
    "files = []\n",
    "ys = []\n",
    "\n",
    "nbatch = (N + batch - 1) // batch\n",
    "for i in tqdm(range(nbatch)):\n",
    "    prompts, yy = zip(*list(make_n_prompts(batch)))\n",
    "    ys.extend(yy)\n",
    "    images = pipe(list(prompts), num_inference_steps=75, guidance_scale=7.5,).images\n",
    "    for j in range(batch):\n",
    "        imname = f\"gen-{i * batch + j + offset}.png\"\n",
    "        files.append(imname)\n",
    "        fname = os.path.join(gendir, imname)\n",
    "        images[j].convert(\"L\").save(fname)\n",
    "\n",
    "mode = \"w\"\n",
    "if offset > 0:\n",
    "    mode = \"a\"\n",
    "with open(os.path.join(gendir, \"metadata.csv\"), mode) as f:\n",
    "    writer = csv.writer(f)\n",
    "    if offset == 0:\n",
    "        writer.writerow([\"file\", \"y\"])\n",
    "    for row in zip(files, ys):\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c246a962",
   "metadata": {},
   "source": [
    "del pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1bc645",
   "metadata": {},
   "source": [
    "# Generated Spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "261dea52",
   "metadata": {},
   "outputs": [],
   "source": [
    "gendir = \"/data/shared/signal-diffusion/parkinsons/gen-stft.1/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8c5ba23d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gen_set = GeneratedSpectrumDataset(gendir)\n",
    "print(len(gen_set))\n",
    "print(gen_set[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82186c9c",
   "metadata": {},
   "source": [
    "## Generative-Trained Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a70c0bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "# Data augmentation\n",
    "randtxfm = transforms.Compose([\n",
    "    transforms.TrivialAugmentWide(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5]),\n",
    "])\n",
    "\n",
    "# Datasets\n",
    "train_set = GeneratedSpectrumDataset(gendir, transform=randtxfm)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE, \n",
    "                                           shuffle=SHUFFLE, num_workers=NUM_WORKERS,\n",
    "                                           pin_memory=True, persistent_workers=persistent)\n",
    "\n",
    "noaug_train_set = GeneratedSpectrumDataset(gendir, transform=None)\n",
    "noaug_train_loader = torch.utils.data.DataLoader(noaug_train_set, batch_size=BATCH_SIZE, \n",
    "                                           shuffle=SHUFFLE, num_workers=NUM_WORKERS,\n",
    "                                           pin_memory=True, persistent_workers=persistent)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=BATCH_SIZE, \n",
    "                                         shuffle=SHUFFLE, num_workers=NUM_WORKERS,\n",
    "                                         pin_memory=True, persistent_workers=persistent)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE, \n",
    "                                          shuffle=SHUFFLE, num_workers=NUM_WORKERS,\n",
    "                                          pin_memory=True, persistent_workers=persistent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d70f12ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters\n",
    "OUTPUT_DIM = 4\n",
    "DROPOUT = 0.5\n",
    "BATCH_FIRST = True # True: (batch, seq, feature). False: (seq, batch, feature)\n",
    "WEIGHT_DECAY = 0.0001\n",
    "\n",
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5916636b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runtime training parameters\n",
    "opt, decay, restart, max_eta, decouple = (torch.optim.AdamW, 0.01, 0, None, True)\n",
    "\n",
    "\n",
    "# Create model instance\n",
    "model = CNNClassifier(1, OUTPUT_DIM, dropout=DROPOUT)\n",
    "model = model.to(device)    \n",
    "if opt == torch.optim.AdamW:\n",
    "    optimizer = opt(model.parameters(), lr=1e-3, weight_decay=decay)\n",
    "else:\n",
    "    optimizer = opt(model.parameters(), weight_decay=decay, max_eta=max_eta, \n",
    "                    decouple_weight_decay=decouple)\n",
    "\n",
    "# Create training configuration\n",
    "ARGS = TrainingConfig(epochs=30, val_every_epochs=3, opt_restart_every=restart)\n",
    "\n",
    "# Log statistics\n",
    "postfix = \"\"\n",
    "if isinstance(optimizer, DoG):\n",
    "    postfix = f\"_restart{restart}_etamax{max_eta}_decouple{str(int(decouple))}\"\n",
    "comment = f\"cnnclass_gen_{str(type(optimizer)).split('.')[-1][:-2]}_decay{decay}{postfix}\"\n",
    "tbsw = SummaryWriter(log_dir=\"./tensorboard_logs/cnn/\" + comment + \"-\" + \n",
    "                     datetime.now().isoformat(sep='_'), \n",
    "                     comment=comment)\n",
    "print(\"#\" * 80)\n",
    "print(\"Training\", comment)\n",
    "\n",
    "# Training loop\n",
    "losses, accs, val_accs = train_class(\n",
    "    ARGS, model, \n",
    "    train_loader, val_loader,\n",
    "    optimizer, criterion,\n",
    "    device, tbsw\n",
    ")\n",
    "\n",
    "# load best model and evaluate on test set\n",
    "model.load_state_dict(torch.load(f'best_model.pt'))\n",
    "test_loss, test_acc = evaluate_class(model, test_loader, criterion, device, \n",
    "                                     tbsw, ARGS.epochs * len(train_loader) + 1)\n",
    "print(f'Test loss={test_loss:.3f}; test accuracy={test_acc:.3f}')\n",
    "\n",
    "# Copy model to unique filename\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "shutil.copyfile(\"best_model.pt\", f\"models/best_model-{comment}.pt\")\n",
    "shutil.copyfile(\"last_model.pt\", f\"models/last_model-{comment}.pt\")\n",
    "print(f\"Copied best model to models/best_model-{comment}.pt\")\n",
    "\n",
    "gmodel = model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11d1edb",
   "metadata": {},
   "source": [
    "### Evaluate on generative data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3344dbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf, p = class_confusion(gmodel, train_loader, parkinsons_class_labels, device)\n",
    "plt.title(\"Gen-train, Gen-test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8eb8ca",
   "metadata": {},
   "source": [
    "### Evaluate on real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "59cfa59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf, p = class_confusion(gmodel, real_train_loader, parkinsons_class_labels, device)\n",
    "plt.title(\"Gen-train, Real-test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aff7e745",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf, p = class_confusion(gmodel, test_loader, parkinsons_class_labels, device)\n",
    "plt.title(\"Gen-train, Real-test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "692213bd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class_prevalence(train_loader, parkinsons_class_labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc03a15c",
   "metadata": {},
   "source": [
    "## Real-trained classifier on generative data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0b51ae24",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmodel = CNNClassifier(1, OUTPUT_DIM,)\n",
    "rmodel.load_state_dict(torch.load(\"models/best_model-cnnclass_AdamW_decay0.001.pt\"))\n",
    "rmodel.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6cc511",
   "metadata": {},
   "source": [
    "### Evaluate on generative data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "25261242",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf, p = class_confusion(rmodel, noaug_train_loader, parkinsons_class_labels, device)\n",
    "plt.title(\"Real-train, Gen-test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490ad540",
   "metadata": {},
   "source": [
    "### Evaluate on real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bf58737e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf, p = class_confusion(rmodel, test_loader, parkinsons_class_labels, device)\n",
    "plt.title(\"Real-train, Real-test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7c4ec4d2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "plt.subplot(2, 2, 1)\n",
    "cf, _ = class_confusion(rmodel, test_loader, parkinsons_class_labels, device, fig=fig)\n",
    "plt.title(\"Real-train, Real-test\")\n",
    "plt.yticks(rotation=60)\n",
    "plt.xticks([])\n",
    "plt.xlabel(\"Accuracy: {:.2%}\".format(np.trace(cf) / np.sum(cf)))\n",
    "plt.ylabel(\"True Class\")\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "cf, _ = class_confusion(rmodel, noaug_train_loader, parkinsons_class_labels, device, fig=fig)\n",
    "plt.xticks([])\n",
    "plt.xlabel(\"Accuracy: {:.2%}\".format(np.trace(cf) / np.sum(cf)))\n",
    "plt.yticks([])\n",
    "plt.title(\"Real-train, Gen-test\")\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "cf, _ = class_confusion(gmodel, test_loader, parkinsons_class_labels, device, fig=fig)\n",
    "plt.title(\"Gen-train, Real-test\")\n",
    "plt.xlabel(\"Predicted Class\\nAccuracy: {:.2%}\".format(np.trace(cf) / np.sum(cf)))\n",
    "plt.yticks(rotation=60)\n",
    "plt.xticks(rotation=60)\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "cf, _ = class_confusion(gmodel, noaug_train_loader, parkinsons_class_labels, device, fig=fig)\n",
    "plt.yticks([])\n",
    "plt.xticks(rotation=60)\n",
    "plt.xlabel(\"Predicted Class\\nAccuracy: {:.2%}\".format(np.trace(cf) / np.sum(cf)))\n",
    "plt.title(\"Gen-train, Gen-test\")\n",
    "\n",
    "plt.subplots_adjust(bottom=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365a9692",
   "metadata": {},
   "source": [
    "## Train on both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "413777fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets\n",
    "both_set = torch.utils.data.ConcatDataset([real_train_set, train_set])\n",
    "both_loader = torch.utils.data.DataLoader(both_set, batch_size=BATCH_SIZE, \n",
    "                                          shuffle=SHUFFLE, num_workers=NUM_WORKERS,\n",
    "                                          pin_memory=True, persistent_workers=persistent)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=BATCH_SIZE, \n",
    "                                         shuffle=SHUFFLE, num_workers=NUM_WORKERS,\n",
    "                                         pin_memory=True, persistent_workers=persistent)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE, \n",
    "                                          shuffle=SHUFFLE, num_workers=NUM_WORKERS,\n",
    "                                          pin_memory=True, persistent_workers=persistent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6cea9b65",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Runtime training parameters\n",
    "opt, decay, restart, max_eta, decouple = (torch.optim.AdamW, 0.01, 0, None, True)\n",
    "\n",
    "\n",
    "# Create model instance\n",
    "model = CNNClassifier(1, OUTPUT_DIM, dropout=DROPOUT)\n",
    "model = model.to(device)    \n",
    "if opt == torch.optim.AdamW:\n",
    "    optimizer = opt(model.parameters(), lr=1e-3, weight_decay=decay)\n",
    "else:\n",
    "    optimizer = opt(model.parameters(), weight_decay=decay, max_eta=max_eta, \n",
    "                    decouple_weight_decay=decouple)\n",
    "\n",
    "# Create training configuration\n",
    "ARGS = TrainingConfig(epochs=15, val_every_epochs=1, opt_restart_every=restart)\n",
    "\n",
    "# Log statistics\n",
    "postfix = \"\"\n",
    "if isinstance(optimizer, DoG):\n",
    "    postfix = f\"_restart{restart}_etamax{max_eta}_decouple{str(int(decouple))}\"\n",
    "comment = f\"cnnclass_both_{str(type(optimizer)).split('.')[-1][:-2]}_decay{decay}{postfix}\"\n",
    "tbsw = SummaryWriter(log_dir=\"./tensorboard_logs/cnn/\" + comment + \"-\" + \n",
    "                     datetime.now().isoformat(sep='_'), \n",
    "                     comment=comment)\n",
    "print(\"#\" * 80)\n",
    "print(\"Training\", comment)\n",
    "\n",
    "# Training loop\n",
    "losses, accs, val_accs = train_class(\n",
    "    ARGS, model, \n",
    "    both_loader, val_loader,\n",
    "    optimizer, criterion,\n",
    "    device, tbsw\n",
    ")\n",
    "\n",
    "# load best model and evaluate on test set\n",
    "model.load_state_dict(torch.load(f'best_model.pt'))\n",
    "test_loss, test_acc = evaluate_class(model, test_loader, criterion, device, \n",
    "                                     tbsw, ARGS.epochs * len(train_loader) + 1)\n",
    "print(f'Test loss={test_loss:.3f}; test accuracy={test_acc:.3f}')\n",
    "\n",
    "# Copy model to unique filename\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "shutil.copyfile(\"best_model.pt\", f\"models/best_model-{comment}.pt\")\n",
    "shutil.copyfile(\"last_model.pt\", f\"models/last_model-{comment}.pt\")\n",
    "print(f\"Copied best model to models/best_model-{comment}.pt\")\n",
    "\n",
    "bmodel = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "29f5412c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf, p = class_confusion(bmodel, test_loader, parkinsons_class_labels, device)\n",
    "plt.title(\"Both-train, Real-test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d2998918",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf, p = class_confusion(bmodel, noaug_train_loader, parkinsons_class_labels, device)\n",
    "plt.title(\"Both-train, Gen-test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eca9bb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
