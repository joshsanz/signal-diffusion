{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1200f947",
   "metadata": {},
   "source": [
    "# Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "798b6201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for Tensor\n",
    "import csv\n",
    "import itertools\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "from collections import OrderedDict\n",
    "from datetime import datetime\n",
    "from tempfile import TemporaryDirectory\n",
    "from typing import Tuple\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, Tensor\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import dataset\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee09d60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.dog import DoG, LDoG, PDoG\n",
    "from models import CNNClassifier\n",
    "from common.eeg_datasets import MathSpectrumDataset, MathPreprocessor\n",
    "from training import train_class, evaluate_class, TrainingConfig\n",
    "from visualization import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68ebe454",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls 'gdrive/My Drive/Muller Group Drive/Ear EEG/Drowsiness_Detection/classifier_TBME'\n",
    "# !ls C:\\Users\\arya_bastani\\Documents\\ear_eeg\\data\\ear_eeg_data\n",
    "ear_eeg_base_path = '/data/shared/signal-diffusion/'\n",
    "# ear_eeg_base_path = '/mnt/d/data/signal-diffusion/'\n",
    "ear_eeg_data_path = ear_eeg_base_path + 'eeg_classification_data/ear_eeg_data/ear_eeg_clean'\n",
    "math_data_path = '/data/shared/signal-diffusion/eeg_math/raw_eeg'\n",
    "# math_data_path = '/mnt/d/data/signal-diffusion/eeg_math/raw_eeg'\n",
    "%ls {ear_eeg_data_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237c1f72",
   "metadata": {},
   "source": [
    "# Data Preprocessing (run once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "101e161a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nsamps = 2000\n",
    "preprocessor = MathPreprocessor(math_data_path, nsamps)\n",
    "\n",
    "samps_per_file = 100\n",
    "#%time preprocessor.preprocess(samps_per_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b939eb8e",
   "metadata": {},
   "source": [
    "# Models and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317852fc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "d = MathSpectrumDataset(math_data_path + \"/train\", 256, 192)\n",
    "print(d[0][0].shape)\n",
    "print(d[0][1].shape)\n",
    "\n",
    "print(len(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989d8f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = torch.utils.data.DataLoader(d, batch_size=16, shuffle=True,)\n",
    "S, y = next(iter(dl))\n",
    "print(S.shape, y.shape)\n",
    "print(S.max(), S.min(), S.mean(), S.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a626f06",
   "metadata": {},
   "source": [
    "# Math EEG Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b3d4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "BATCH_SIZE = 64\n",
    "SHUFFLE = True\n",
    "NUM_WORKERS = 16\n",
    "N_TOKENS = 128\n",
    "RESOLUTION = 256\n",
    "HOP_LENGTH = 192\n",
    "persistent = NUM_WORKERS > 0\n",
    "\n",
    "# Datasets\n",
    "train_set = MathSpectrumDataset(math_data_path + \"/train\", RESOLUTION, HOP_LENGTH)\n",
    "val_set = MathSpectrumDataset(math_data_path + \"/val\", RESOLUTION, HOP_LENGTH)\n",
    "test_set = MathSpectrumDataset(math_data_path + \"/test\", RESOLUTION, HOP_LENGTH)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE, \n",
    "                                           shuffle=SHUFFLE, num_workers=NUM_WORKERS,\n",
    "                                           pin_memory=True, persistent_workers=persistent)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=BATCH_SIZE, \n",
    "                                         shuffle=SHUFFLE, num_workers=NUM_WORKERS,\n",
    "                                         pin_memory=True, persistent_workers=persistent)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE, \n",
    "                                          shuffle=SHUFFLE, num_workers=NUM_WORKERS,\n",
    "                                          pin_memory=True, persistent_workers=persistent)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "414ea53c",
   "metadata": {},
   "source": [
    "import time\n",
    "# Warmup\n",
    "for i, (X, y) in enumerate(train_loader):\n",
    "    count = i\n",
    "    if i >= 100:\n",
    "        break\n",
    "# Measure\n",
    "t0 = time.time()\n",
    "count = 0\n",
    "for i, (X, y) in enumerate(train_loader):\n",
    "    count = i\n",
    "    if i >= 100:\n",
    "        break\n",
    "t1 = time.time()\n",
    "print(f\"Achieved {(t1 - t0) / count} s/it\")\n",
    "print(\"or\")\n",
    "print(f\"Achieved {count / (t1 - t0)} it/s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787c1b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters\n",
    "OUTPUT_DIM = 4\n",
    "DROPOUT = 0.25\n",
    "BATCH_FIRST = True # True: (batch, seq, feature). False: (seq, batch, feature)\n",
    "WEIGHT_DECAY = 0.0001\n",
    "\n",
    "# CUDA for PyTorch\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "torch.backends.cudnn.benchmark = device.type == \"cuda\"\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39683b1d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Runtime training parameters\n",
    "opt_options = [\n",
    "    torch.optim.AdamW,\n",
    "    LDoG,\n",
    "    # PDoG,\n",
    "    DoG,\n",
    "]\n",
    "restart_options = [0, 100]\n",
    "# restart_options = [0]\n",
    "max_eta_options = [None, 100.]\n",
    "# max_eta_options = [None]\n",
    "# decay_options = [0.0, 0.0001, 0.001]\n",
    "decay_options = [0.0001, 0.001]\n",
    "# decouple_options = [True, False]\n",
    "decouple_options = [True]\n",
    "\n",
    "# Run for each option combo\n",
    "seen_decays = set()\n",
    "combos = list(itertools.product(\n",
    "    opt_options, decay_options, restart_options, max_eta_options, decouple_options))\n",
    "print(f\"Running {len(combos)} hyperparameter tests\")\n",
    "for (opt, decay, restart, max_eta, decouple) in combos:\n",
    "    # Only run once for AdamW, decay combos\n",
    "    if opt == torch.optim.AdamW:\n",
    "        continue\n",
    "        if decay in seen_decays:\n",
    "            continue\n",
    "        seen_decays.add(decay)\n",
    "\n",
    "    # Create model instance\n",
    "    model = CNNClassifier(1, OUTPUT_DIM,)\n",
    "    model = model.to(device)    \n",
    "    if opt == torch.optim.AdamW:\n",
    "        optimizer = opt(model.parameters(), lr=1e-3, weight_decay=decay)\n",
    "    else:\n",
    "        optimizer = opt(model.parameters(), weight_decay=decay, max_eta=max_eta, decouple_weight_decay=decouple)\n",
    "\n",
    "    # Create training configuration\n",
    "    ARGS = TrainingConfig(epochs=300, val_every_epochs=10, opt_restart_every=restart)\n",
    "\n",
    "    # Log statistics\n",
    "    postfix = \"\"\n",
    "    if isinstance(optimizer, DoG):\n",
    "        postfix = f\"_restart{restart}_etamax{max_eta}_decouple{str(int(decouple))}\"\n",
    "    comment = f\"cnnclass_{str(type(optimizer)).split('.')[-1][:-2]}_decay{decay}{postfix}\"\n",
    "    tbsw = SummaryWriter(log_dir=\"./tensorboard_logs/cnn/\" + comment + \"-\" + datetime.now().isoformat(sep='_'), \n",
    "                         comment=comment)\n",
    "    print(\"#\" * 80)\n",
    "    print(\"Training\", comment)\n",
    "\n",
    "    # Training loop\n",
    "    losses, accs, val_accs = train_class(\n",
    "        ARGS, model, \n",
    "        train_loader, val_loader,\n",
    "        optimizer, criterion,\n",
    "        device, tbsw\n",
    "    )\n",
    "    \n",
    "    # load best model and evaluate on test set\n",
    "    model.load_state_dict(torch.load(f'best_model.pt'))\n",
    "    test_loss, test_acc = evaluate_class(model, test_loader, criterion, device, tbsw, ARGS.epochs * len(train_loader) + 1)\n",
    "    print(f'Test loss={test_loss:.3f}; test accuracy={test_acc:.3f}')\n",
    "\n",
    "    # Copy model to unique filename\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    shutil.copyfile(\"best_model.pt\", f\"models/best_model-{comment}.pt\")\n",
    "    shutil.copyfile(\"last_model.pt\", f\"models/last_model-{comment}.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d0dd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf, p = class_confusion(model, train_loader, math_class_map, device)\n",
    "plt.title(\"Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cece69",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf, p = class_confusion(model, val_loader, math_class_map, device)\n",
    "plt.title(\"Validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49abcb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf, p = class_confusion(model, test_loader, math_class_map, device)\n",
    "plt.title(\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8de8e69",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class_prevalence(train_loader, math_class_map);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54b6ec5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
