import numpy as np
import torch
import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib.ticker as ticker

from common.eeg_datasets import math_class_labels


def class_confusion(model, data_loader, class_map, device='cpu', fig=None):
    model.eval()
    nclass = len(class_map)
    confusion = np.zeros((nclass, nclass), dtype=np.int32)
    for X, y in data_loader:
        with torch.no_grad():
            logits = model(X.to(device))
        y_hat = torch.argmax(logits, dim=-1)
        for true, pred in zip(y, y_hat):
            confusion[true, pred] += 1

    make_labels = False
    if fig is None:
        fig, _ = plt.subplots()
        make_labels = True
    sns.heatmap(confusion / np.sum(confusion, axis=0, keepdims=True), annot=True, fmt=".2%", cmap="Blues",
                xticklabels=class_map.values(), yticklabels=class_map.values())
    if make_labels:
        plt.yticks(rotation=60)
        plt.xlabel("Predicted Class\nAccuracy: {:.2%}".format(np.trace(confusion) / np.sum(confusion)))
        plt.ylabel("True Class")
    return confusion, fig


def class_prevalence(data_loader, class_map):

    nclass = len(class_map)
    counts = np.zeros(nclass, dtype=np.int32)
    for _, y in data_loader:
        for c in y:
            counts[c] += 1
    p = plt.figure()
    plt.xlabel("Class")
    plt.ylabel("Percent of Samples")
    plt.bar(class_map.values(), counts / np.sum(counts))
    plt.gca().yaxis.set_major_formatter(ticker.PercentFormatter(xmax=1.0, decimals=1))
    return p


# Holy crap this entire function body was autogenerated by copilot!
def raw_class_confusion(ys, yhats, class_map=math_class_labels):
    nclass = len(class_map)
    confusion = np.zeros((nclass, nclass), dtype=np.int32)
    for true, pred in zip(ys, yhats):
        confusion[true, pred] += 1

    fig, _ = plt.subplots()
    sns.heatmap(confusion / np.sum(confusion, axis=0, keepdims=True), annot=True, fmt=".2%", cmap="Blues",
                xticklabels=class_map.values(), yticklabels=class_map.values())
    plt.yticks(rotation=60)
    plt.xlabel("Predicted Class\nAccuracy: {:.2%}".format(np.trace(confusion) / np.sum(confusion)))
    plt.ylabel("True Class")
    return confusion, fig


# This one too!
def raw_class_prevalence(ys, class_map=math_class_labels):
    nclass = len(class_map)
    counts = np.zeros(nclass, dtype=np.int32)
    for c in ys:
        counts[c] += 1
    p = plt.figure()
    plt.xlabel("Class")
    plt.ylabel("Percent of Samples")
    plt.bar(class_map.values(), counts / np.sum(counts))
    plt.gca().yaxis.set_major_formatter(ticker.PercentFormatter(xmax=1.0, decimals=1))
    return p
