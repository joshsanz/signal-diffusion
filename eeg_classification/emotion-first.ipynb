{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for Tensor\n",
    "import csv\n",
    "import itertools\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import sys\n",
    "from collections import OrderedDict\n",
    "from datetime import datetime\n",
    "from tempfile import TemporaryDirectory\n",
    "from typing import Tuple\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, Tensor\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from datasets import load_dataset\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MetaDataset configuration\n",
    "train_dataset_names = ('parkinsons', 'seed')\n",
    "target_tasks = (\"gender\",)\n",
    "\n",
    "val_set = MetaDataset(\n",
    "    settings,\n",
    "    train_dataset_names,\n",
    "    split=\"val\",\n",
    "    tasks=target_tasks,\n",
    "    target_format=\"tuple\",\n",
    ")\n",
    "\n",
    "real_train_set = MetaDataset(\n",
    "    settings,\n",
    "    train_dataset_names,\n",
    "    split=\"train\",\n",
    "    tasks=target_tasks,\n",
    "    transform=randtxfm,\n",
    "    target_format=\"tuple\",\n",
    ")\n",
    "\n",
    "train_samp = MetaSampler(real_train_set, num_samples=len(real_train_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 205 #205 Gave a good split for training\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datapaths\n",
    "datadirs = {}\n",
    "# datahome = '/data/shared/signal-diffusion'\n",
    "datahome = '/mnt/d/data/signal-diffusion'\n",
    "\n",
    "# Math dataset\n",
    "datadirs['math'] = f'{datahome}/eeg_math'\n",
    "datadirs['math-stft'] = os.path.join(datadirs['math'], 'stfts')\n",
    "\n",
    "# Parkinsons dataset\n",
    "datadirs['parkinsons'] = f'{datahome}/parkinsons/'\n",
    "datadirs['parkinsons-stft'] = os.path.join(datadirs['parkinsons'], 'stfts')\n",
    "\n",
    "#SEED dataset\n",
    "datadirs['seed'] = f'{datahome}/seed/'\n",
    "datadirs['seed-stft'] = os.path.join(datadirs['seed'], \"stfts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamps = 2000\n",
    "\n",
    "preprocessor = GeneralPreprocessor(datadirs, nsamps, ovr_perc=0.5, fs=125) \n",
    "#preprocessor.preprocess(resolution=256, train_frac=0.8, val_frac=0.2, test_frac=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "BATCH_SIZE = 64\n",
    "SHUFFLE = True\n",
    "NUM_WORKERS = 4\n",
    "N_TOKENS = 128\n",
    "RESOLUTION = 256\n",
    "HOP_LENGTH = 80\n",
    "persistent = NUM_WORKERS > 0\n",
    "\n",
    "# Data augmentation\n",
    "randtxfm = transforms.Compose([\n",
    "    transforms.TrivialAugmentWide(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets, excluding math\n",
    "math_val_dataset = MathDataset(datadirs['math-stft'], split=\"val\")\n",
    "parkinsons_val_dataset = ParkinsonsDataset(datadirs['parkinsons-stft'], split=\"val\")\n",
    "seed_val_dataset = SEEDDataset(datadirs['seed-stft'], split=\"val\")\n",
    "val_datasets = [parkinsons_val_dataset, seed_val_dataset]\n",
    "\n",
    "math_real_train_dataset = MathDataset(datadirs['math-stft'], split=\"train\")\n",
    "parkinsons_real_train_dataset = ParkinsonsDataset(datadirs['parkinsons-stft'], split=\"train\", transform=None)\n",
    "seed_real_train_dataset = SEEDDataset(datadirs['seed-stft'], split=\"train\")\n",
    "real_train_datasets = [parkinsons_real_train_dataset, seed_real_train_dataset]\n",
    "\n",
    "\n",
    "val_set = GeneralDataset(val_datasets, split='val')\n",
    "real_train_set = GeneralDataset(real_train_datasets, split='train')\n",
    "\n",
    "# Sampler for balanced training data\n",
    "train_samp = GeneralSampler(real_train_datasets, BATCH_SIZE, split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloaders\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=SHUFFLE,\n",
    "                                         num_workers=NUM_WORKERS, pin_memory=True, \n",
    "                                         persistent_workers=persistent)\n",
    "real_train_loader = torch.utils.data.DataLoader(real_train_set, batch_size=BATCH_SIZE, \n",
    "                                                num_workers=NUM_WORKERS, pin_memory=True, \n",
    "                                                persistent_workers=persistent, sampler=train_samp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters\n",
    "OUTPUT_DIM = {\"gender\": 2, \"health\": 2, \"emotion\": 5}\n",
    "DROPOUT = 0.7\n",
    "BATCH_FIRST = True # True: (batch, seq, feature). False: (seq, batch, feature)\n",
    "\n",
    "# CUDA for PyTorch\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "torch.backends.cudnn.benchmark = device.type == \"cuda\"\n",
    "\n",
    "# Loss function\n",
    "criterion = LabelSmoothingCrossEntropy(epsilon=0.2)\n",
    "\n",
    "# Schedulers\n",
    "scheduler = True\n",
    "sched_gamma = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_val_dataset = SEEDDataset(datadirs['seed-stft'], split=\"val\", task=\"emotion\")\n",
    "seed_real_train_dataset = SEEDDataset(datadirs['seed-stft'], split=\"train\", task=\"emotion\")\n",
    "# Sampler for balanced training data\n",
    "emotion_samp = EmotionSampler(datadirs['seed-stft'], BATCH_SIZE, split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloaders\n",
    "seed_val_loader = torch.utils.data.DataLoader(seed_val_dataset, batch_size=BATCH_SIZE, shuffle=SHUFFLE,\n",
    "                                         num_workers=NUM_WORKERS, pin_memory=True, \n",
    "                                         persistent_workers=persistent)\n",
    "seed_real_train_loader = torch.utils.data.DataLoader(seed_real_train_dataset, batch_size=BATCH_SIZE, \n",
    "                                                num_workers=NUM_WORKERS, pin_memory=True, \n",
    "                                                persistent_workers=persistent, sampler=emotion_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet(out_dim=OUTPUT_DIM['emotion'], layers=[1, 1, 2, 1])\n",
    "model.to(\"cuda\");\n",
    "\n",
    "# SWA model instance\n",
    "swa_model = torch.optim.swa_utils.AveragedModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runtime training parameters\n",
    "opt, decay, restart, max_eta, decouple = (torch.optim.AdamW, 0.25, 0, None, True)\n",
    "\n",
    "optimizer = opt(model.parameters(), lr=5e-5, weight_decay=decay)\n",
    "\n",
    "# Learning rate scheduler\n",
    "if scheduler == True:\n",
    "    # scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, sched_gamma, last_epoch=- 1, verbose=False)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=8)\n",
    "    swa_scheduler = scheduler\n",
    "\n",
    "    # = torch.optim.swa_utils.SWALR(optimizer, swa_lr=0.05)\n",
    "\n",
    "\n",
    "# Create training configuration\n",
    "swa_start=1000\n",
    "ARGS = TrainingConfig(epochs=15, val_every_epochs=1, opt_restart_every=restart, swa_start=swa_start,\n",
    "                      task=None)\n",
    "\n",
    "# Log statistics\n",
    "postfix = \"_emotion\"\n",
    "comment = f\"cnnclass_{model.name}_{str(type(optimizer)).split('.')[-1][:-2]}_decay{decay}{postfix}\"\n",
    "tbsw = SummaryWriter(log_dir=\"./tensorboard_logs/cnn/\" + comment + \"-\" + \n",
    "                     datetime.now().isoformat(sep='_'), \n",
    "                     comment=comment)\n",
    "print(\"#\" * 80)\n",
    "print(\"Training\", comment)\n",
    "\n",
    "# Training loop\n",
    "losses, accs, val_accs = train_class(\n",
    "    ARGS, model, swa_model,\n",
    "    seed_real_train_loader, seed_val_loader,\n",
    "    optimizer, scheduler, \n",
    "    criterion, device, tbsw\n",
    ")\n",
    "\n",
    "# load best model and evaluate on test set\n",
    "model.load_state_dict(torch.load(f'best_model.pt'))\n",
    "# test_loss, test_acc = evaluate_class(model, test_loader, criterion, device, \n",
    "#                                      tbsw, ARGS.epochs * len(real_train_loader) + 1)\n",
    "# print(f'Test loss={test_loss:.3f}; test accuracy={test_acc:.3f}')\n",
    "\n",
    "# Copy model to unique filename\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "shutil.copyfile(\"best_model.pt\", f\"models/best_model-{comment}.pt\")\n",
    "shutil.copyfile(\"last_model.pt\", f\"models/last_model-{comment}.pt\")\n",
    "print(f\"Copied best model to models/best_model-{comment}.pt\")\n",
    "\n",
    "rmodel = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf, p = class_confusion(rmodel, seed_val_loader, emotion_class_labels, device, task=\"emotion\")\n",
    "plt.title(\"Emotion Validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model instance\n",
    "model = CNNClassifierLight(1, OUTPUT_DIM, dropout=DROPOUT,pooling=\"max\")\n",
    "model = model.to(device)    \n",
    "\n",
    "# SWA model instance\n",
    "swa_model = torch.optim.swa_utils.AveragedModel(model)\n",
    "swa_start = 12\n",
    "\n",
    "# Runtime training parameters\n",
    "opt, decay, restart, max_eta, decouple = (torch.optim.AdamW, 0.05, 0, None, True)\n",
    "\n",
    "optimizer = opt(model.parameters(), lr=5e-4, weight_decay=decay)\n",
    "\n",
    "# Learning rate scheduler\n",
    "if scheduler == True:\n",
    "    # scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, sched_gamma, last_epoch=- 1, verbose=False)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=8)\n",
    "    swa_scheduler = scheduler\n",
    "\n",
    "    # = torch.optim.swa_utils.SWALR(optimizer, swa_lr=0.05)\n",
    "\n",
    "\n",
    "# Create training configuration\n",
    "ARGS = TrainingConfig(epochs=15, val_every_epochs=1, opt_restart_every=restart, swa_start=swa_start,\n",
    "                      task=\"gender\")\n",
    "\n",
    "# Log statistics\n",
    "postfix = \"\"\n",
    "comment = f\"cnnclass_{model.name}_{str(type(optimizer)).split('.')[-1][:-2]}_decay{decay}{postfix}\"\n",
    "tbsw = SummaryWriter(log_dir=\"./tensorboard_logs/cnn/\" + comment + \"-\" + \n",
    "                     datetime.now().isoformat(sep='_'), \n",
    "                     comment=comment)\n",
    "print(\"#\" * 80)\n",
    "print(\"Training\", comment)\n",
    "\n",
    "# Training loop\n",
    "losses, accs, val_accs = train_class(\n",
    "    ARGS, model, swa_model,\n",
    "    real_train_loader, val_loader,\n",
    "    optimizer, scheduler, \n",
    "    criterion, device, tbsw\n",
    ")\n",
    "\n",
    "# load best model and evaluate on test set\n",
    "model.load_state_dict(torch.load(f'best_model.pt'))\n",
    "# test_loss, test_acc = evaluate_class(model, test_loader, criterion, device, \n",
    "#                                      tbsw, ARGS.epochs * len(real_train_loader) + 1)\n",
    "# print(f'Test loss={test_loss:.3f}; test accuracy={test_acc:.3f}')\n",
    "\n",
    "# Copy model to unique filename\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "shutil.copyfile(\"best_model.pt\", f\"models/best_model-{comment}.pt\")\n",
    "shutil.copyfile(\"last_model.pt\", f\"models/last_model-{comment}.pt\")\n",
    "print(f\"Copied best model to models/best_model-{comment}.pt\")\n",
    "\n",
    "rmodel = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf, p = class_confusion(rmodel, val_loader, general_class_labels, device)\n",
    "plt.title(\"MAIN Validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = roc(model, val_loader, label=\"gender\", task=\"gender\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train - Other Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable grads for conv layers\n",
    "for p in model.convs.parameters():\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(\"cuda\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "parkinsons_val_dataset = ParkinsonsDataset(datadirs['parkinsons-stft'], split=\"val\", task=\"health\")\n",
    "parkinsons_real_train_dataset = ParkinsonsDataset(datadirs['parkinsons-stft'], split=\"train\", transform=None, task=\"health\")\n",
    "# Sampler for balanced training data\n",
    "health_samp = HealthSampler(datadirs['parkinsons-stft'], BATCH_SIZE, split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloaders\n",
    "parkinsons_val_loader = torch.utils.data.DataLoader(parkinsons_val_dataset, batch_size=BATCH_SIZE, shuffle=SHUFFLE,\n",
    "                                         num_workers=NUM_WORKERS, pin_memory=True, \n",
    "                                         persistent_workers=persistent)\n",
    "parkinsons_real_train_loader = torch.utils.data.DataLoader(parkinsons_real_train_dataset, batch_size=BATCH_SIZE, \n",
    "                                                num_workers=NUM_WORKERS, pin_memory=True, \n",
    "                                                persistent_workers=persistent, sampler=health_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runtime training parameters\n",
    "opt, decay, restart, max_eta, decouple = (torch.optim.AdamW, 0.05, 0, None, True)\n",
    "\n",
    "optimizer = opt(model.fcs[\"health\"].parameters(), lr=5e-4, weight_decay=decay)\n",
    "\n",
    "# Learning rate scheduler\n",
    "if scheduler == True:\n",
    "    # scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, sched_gamma, last_epoch=- 1, verbose=False)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=8)\n",
    "    swa_scheduler = scheduler\n",
    "\n",
    "    # = torch.optim.swa_utils.SWALR(optimizer, swa_lr=0.05)\n",
    "\n",
    "\n",
    "# Create training configuration\n",
    "swa_start=1000\n",
    "ARGS = TrainingConfig(epochs=75, val_every_epochs=1, opt_restart_every=restart, swa_start=swa_start,\n",
    "                      task=\"health\")\n",
    "\n",
    "# Log statistics\n",
    "postfix = \"_health\"\n",
    "comment = f\"cnnclass_{model.name}_{str(type(optimizer)).split('.')[-1][:-2]}_decay{decay}{postfix}\"\n",
    "tbsw = SummaryWriter(log_dir=\"./tensorboard_logs/cnn/\" + comment + \"-\" + \n",
    "                     datetime.now().isoformat(sep='_'), \n",
    "                     comment=comment)\n",
    "print(\"#\" * 80)\n",
    "print(\"Training\", comment)\n",
    "\n",
    "# Training loop\n",
    "losses, accs, val_accs = train_class(\n",
    "    ARGS, model, swa_model,\n",
    "    parkinsons_real_train_loader, parkinsons_val_loader,\n",
    "    optimizer, scheduler, \n",
    "    criterion, device, tbsw\n",
    ")\n",
    "\n",
    "# load best model and evaluate on test set\n",
    "model.load_state_dict(torch.load(f'best_model.pt'))\n",
    "# test_loss, test_acc = evaluate_class(model, test_loader, criterion, device, \n",
    "#                                      tbsw, ARGS.epochs * len(real_train_loader) + 1)\n",
    "# print(f'Test loss={test_loss:.3f}; test accuracy={test_acc:.3f}')\n",
    "\n",
    "# Copy model to unique filename\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "shutil.copyfile(\"best_model.pt\", f\"models/best_model-{comment}.pt\")\n",
    "shutil.copyfile(\"last_model.pt\", f\"models/last_model-{comment}.pt\")\n",
    "print(f\"Copied best model to models/best_model-{comment}.pt\")\n",
    "\n",
    "rmodel = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf, p = class_confusion(rmodel, parkinsons_val_loader, health_class_labels, device, task=\"health\")\n",
    "plt.title(\"Health Validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = roc(model, parkinsons_val_loader, label=\"health\", task=\"health\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
